---
title: "Take Home Exercise 1"
author: "Oh Jia Wen"
date: 11/25/2023
date-modified: "last-modified"
execute: 
  echo: true
  eval: true
  warning: false
---

# 1. Overview

The digitization of city-wide urban infrastructures such as buses,mass rapid transit enable collection of massive data sets on patterns such as human movement and behaviors within the city. In real-world practices, the use of these data are confined to simple tracking and mapping with GIS applications due to the lack of functions in conventional GIS.

## 1.1 The Task

This exercise aims to reveals the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore using appropriate geovisualisation techniques and analysis.

The original data set was downloaded on 18th November 2023 from **LTA DataMall** under Section 2.6 - *Passenger Volume by Origin Destination Bus Stops*. It records the number of trips by weekdays and weekends from origin to destination bus stops. For the purpose of this exercise, we will be using the **August** data :

-   origin_destination_bus_202308.csv

# 2. Data preparation

## 2.1 Install R packages

The code chunk below uses `pacman:: p_load()` to load and install the following libraries:

-   **`mapview`** : Used to create interactive visualization of spatial data

-   **`knitr`**: Used for dynamic report generation

-   **`patchwork`** : Used to combine multiple ggplot graphs into the same graphic

-   **`sf`** : Used for geospatial data handling

-   `spdep` : Used to create spatial weights matrix objects

-   **`sfdep`** : Used to integrate with `'sf'` objects and the `'tidyverse'`

-   **`tidyverse`**: A collection of R packages use in everyday data analyses. It is able to support data science, data wrangling, and analysis

-   **`tmap`** : Used for thematic mapping

```{r}
pacman::p_load(mapview, knitr, patchwork, sf, spdep, sfdep, tidyverse, tmap)
```

## 2.2 Import and Load Dataset

Aspatial data and a hexagon layer will be used for this study :

-   `origin_destination_bus_202308.csv` : A csv file containing information about all the bus stops currently being serviced by bus, which includes bus stop identifier, and location coordinates.

-   `hexagon` : A hexagon layer of 250m to replace the relative coarse and irregular Master Plan 2019 Planning Sub-Zone GIS data of URA

### 2.2.1 Importing Aspatial data

First, we will import the [Passenger Volume by Origin Destination Bus Stops]{.underline} data set for **August** by using `readr::read_csv()` and store it in variable **odbus**. Also, we will be using `glimpse()` report to reveal the data type of each field.

*Point to note: `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` are in `<chr>` format.*

```{r}
#| code-fold: true
odbus <- read_csv("data/aspatial/origin_destination_bus_202308.csv")
glimpse(odbus)
```

### 2.2.2 Importing Geospatial data

Thereafter, we will import the [Passenger Volume by Origin Destination Bus Stops]{.underline} data set for **August**.

#### 2.2.2.1 Import Bus Stop data

We will be using `sf::st_read()` to import and `sf::st_transform()` to ensure that the projected coordinate system is in the right format before storing in variable **busstop**. Also, we will be using `glimpse()` report to reveal the data type of each field.

```{r}
busstop <- st_read(dsn = "data/geospatial",layer = "BusStop") %>%
    st_transform(crs = 3414)
```

The message above shows that there are a total of 5161 features and 3 fields in `busstop` point feature data frame and it is in **SVY21** projected coordinates system.

```{r}
glimpse(busstop)
```

::: {.callout-note title="Note about coordinates system " collapse="true"}
## Note about coordinates system

crs : to provide the coordinates system in EPSG format.

EPSG: 4326 is wgs84 Geographic Coordinate System

EPSG : 3414 is Singapore SVY21 Projected Coordinate System.

For more information, do refer to [epsg.io](https://epsg.io/)
:::

## 2.3 Data Wrangling

Looking at the section 2.2.1, we noticed a few problem:

-   *`ORIGIN_PT_CODE`* : is in `<chr>` format.

-   *`DESTINATION_PT_CODE`* : is in `<chr>` format.

We will be using `dplyr::mutate()` to convert the `<chr>` data type to `<fct>` and store it in a new variable **odbus_new**.

```{r}
#| code-fold: true
odbus_new <- odbus %>%
 mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),
        DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE))

glimpse(odbus_new)

```

Additionally, we confirmed that there are no missing values in the **odbus_new data set.**

```{r}
any(is.na(odbus_new))
```

### 2.3.1 Data Extraction

In this section, we will extract commuting flows based on the table below.

| Peak hour period             | Bus tap on time |
|------------------------------|-----------------|
| Weekday morning peak         | 6am to 9am      |
| Weekday afternoon peak       | 5pm to 8pm      |
| Weekend/holiday morning peak | 11am to 2pm     |
| Weekend/holiday evening peak | 4pm to 7pm      |

The code is extracted in the following manner:

-   `filter()` is used to extract subset of data

-   `between()` is used to express a range condition

-   `group_by()` and `summarise()` are used to sum the total trips

-   `arrange(desc())` to sort in descending order

-   `ungroup()` is used to end a definition, often use with `group_by()`

```{r}
#| code-fold: true

#weekday morning peak 
wkd6_9 <- odbus_new %>%
  filter(DAY_TYPE == "WEEKDAY",
         between(TIME_PER_HOUR, 6, 9)) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  arrange(desc(TRIPS)) %>%
  ungroup()

#weekday afternoon peak 
wkd17_20 <- odbus_new %>%
  filter(DAY_TYPE == "WEEKDAY",
         between(TIME_PER_HOUR, 17, 20)) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  arrange(desc(TRIPS)) %>%
  ungroup()

#weekend/holiday morning peak 
wknd11_14 <- odbus_new %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY",
         between(TIME_PER_HOUR, 11, 14)) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  arrange(desc(TRIPS)) %>%
  ungroup()

#weekend/holiday afternoon peak 
wknd16_19 <- odbus_new %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY",
         between(TIME_PER_HOUR, 16, 19)) %>%
  group_by(ORIGIN_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%
  arrange(desc(TRIPS)) %>%
  ungroup()


```

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| eval: true
kable(head(wkd6_9))
```

# Weekday (1700-2000)

```{r}
#| eval: true
kable(head(wkd17_20))
```

# Weekends/Holidays (1100-1400)

```{r}
#| eval: true
kable(head(wknd11_14))
```

# Weekends/Holidays (1600-1900)

```{r}
#| eval: true
kable(head(wknd16_19))
```
:::

Thereafter, we will save a copy of the output in rds format and reload it into the environment.

```{r}
#| code-fold: true
#weekday morning peak 
write_rds(wkd6_9, "data/rds/wkd6_9.rds")
wkd6_9 <- read_rds("data/rds/wkd6_9.rds")

#weekday afternoon peak 
write_rds(wkd17_20, "data/rds/wkd17_20.rds")
wkd17_20 <- read_rds("data/rds/wkd17_20.rds")

#weekend/holiday morning peak 
write_rds(wknd11_14, "data/rds/wknd11_14.rds")
wknd11_14 <- read_rds("data/rds/wknd11_14.rds")

#weekend/holiday afternoon peak 
write_rds(wknd16_19, "data/rds/wknd16_19.rds")
wknd16_19 <- read_rds("data/rds/wknd16_19.rds")
```

### 2.3.2 Combining Data

Before we proceed, we will used `mapview()` as a default visualization.

```{r}
#| code-fold: true
mapview_check = mapview(busstop, cex = 3, alpha = .5, popup = NULL)

mapview_check
```

As observed, there are [5 bus stops]{.underline} that are not within Singapore Map that includes [Passenger Volume by Origin Destination Bus Stop.]{.underline} Although we are able to filter and remove bus stops that are not within the Singapore Boundary, it might be interesting to observe the community flows from Singapore to Johor Bahru. As such we will not remove these data points.

#### 2.3.2.1 Combine commuting flow into busstop

After populating the commuting flow, we will combine it into **busstop** sf data frame. To ensure that all bus stops are distinct, we will be using `dplyr:: mutate()` to replace N/A to 0 and add `unique()` function into our code to keep distinct flows.

```{r}
#| code-fold: true
#weekday morning peak 
origin_SZ_wkd6_9 <- left_join(busstop, wkd6_9,
            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  unique() %>%
  ungroup()

#weekday afternoon peak 
origin_SZ_wkd17_20 <- left_join(busstop, wkd17_20,
            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  unique() %>%
  ungroup()

#weekend/holiday morning peak 
origin_SZ_wknd11_14 <- left_join(busstop, wknd11_14,
            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  unique() %>%
  ungroup()

#weekend/holiday afternoon peak 
origin_SZ_wknd16_19 <- left_join(busstop, wknd16_19,
            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE")) %>%
      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  unique() %>%
  ungroup()
```

#### 2.3.2.2 Create Hexagon Layer

Hexagons are the densest way to pack circles in tessellation and reduce **edge effects**. With reference to [Urban Data Palette](https://urbandatapalette.com/post/2021-08-tessellation-sf/), we will create honeycomb grid through the following steps:

-   `st_make_grid()` : create a regular grid of spatial polygons. Revision have been done to the cell width and height to c(500,500).

-   `st_sf()` : convert the honeycomb grid object to an sf object. Grid ID is created to count the number of bus stops and sum of trips in the grid.

-   `st_intersects()` : determine whether two sets of spatial objects intersect.

-   `st_join()` : join two spatial objects based on their spatial relationships by intersections.

```{r}
#| code-fold: true
#weekday morning peak 
honeycomb_grid_wkd6_9 = st_make_grid(origin_SZ_wkd6_9, c(500, 500), #cell revised
                              what = "polygons", square = FALSE)
honeycomb_grid_sf_0609 = st_sf(honeycomb_grid_wkd6_9) %>%
  mutate(grid_id = 1:length(lengths(honeycomb_grid_wkd6_9)))
intersections0609 <- st_intersects(origin_SZ_wkd6_9, honeycomb_grid_sf_0609)
join_df0609 <- st_join(honeycomb_grid_sf_0609, origin_SZ_wkd6_9, by = intersections0609)

#weekday afternoon peak 
honeycomb_grid_wkd17_20 = st_make_grid(origin_SZ_wkd17_20, c(500, 500), 
                              what = "polygons", square = FALSE)
honeycomb_grid_sf_1720 = st_sf(honeycomb_grid_wkd17_20) %>%
  mutate(grid_id = 1:length(lengths(honeycomb_grid_wkd17_20)))
intersections1720 <- st_intersects(origin_SZ_wkd17_20, honeycomb_grid_sf_1720)
join_df1720 <- st_join(honeycomb_grid_sf_1720, origin_SZ_wkd17_20, by = intersections1720)

#weekend/holiday morning peak 
honeycomb_grid_wknd11_14 = st_make_grid(origin_SZ_wknd11_14, c(500, 500), 
                              what = "polygons", square = FALSE)
honeycomb_grid_sf_1114 = st_sf(honeycomb_grid_wknd11_14) %>%
  mutate(grid_id = 1:length(lengths(honeycomb_grid_wknd11_14)))
intersections1114 <- st_intersects(origin_SZ_wknd11_14, honeycomb_grid_sf_1114)
join_df1114 <- st_join(honeycomb_grid_sf_1114, origin_SZ_wknd11_14, by = intersections1114)

#weekend/holiday afternoon peak 
honeycomb_grid_wknd16_19 = st_make_grid(origin_SZ_wknd16_19, c(500, 500), 
                              what = "polygons", square = FALSE)
honeycomb_grid_sf_1619 = st_sf(honeycomb_grid_wknd16_19) %>%
  mutate(grid_id = 1:length(lengths(honeycomb_grid_wknd16_19)))
intersections1619 <- st_intersects(origin_SZ_wknd16_19, honeycomb_grid_sf_1619)
join_df1619 <- st_join(honeycomb_grid_sf_1619, origin_SZ_wknd16_19, by = intersections1619)

```

#### 2.3.2.3 Extract Data

After creating the joined data frame, we are interested in knowing the number of bus stops that is in the grid_id and the total number of trips. As such, we performed the following steps:

-   `mutate()` : Used to replace TRIPS with N/A to 0.

-   `filter()` : Used to remove data with 0 trip

-   `group_by()`: Used to group data based on **grid_id**.

-   `summarize()` :

    -   `n()` : Used to count number of bus stops and save as *bus_stop_count*

    -   `sum()` : Used to sum the TRIPS values and save as *total_trips*

-   `ungroup()` : Used to end a definition, often use with `group_by()`

```{r}
#| code-fold: true
#weekday morning peak 
join_df_wkd6_9_group <- join_df0609 %>%
        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  filter(TRIPS > 0) %>%
  group_by(grid_id) %>%
  summarize(
    bus_stop_count = n(),
    total_trips = sum(TRIPS)
  ) %>%
  ungroup()

#weekday afternoon peak 
join_df_wkd17_20_group <- join_df1720 %>%
        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  filter(TRIPS > 0) %>%
  group_by(grid_id) %>%
  summarize(
    bus_stop_count = n(),
    total_trips = sum(TRIPS)
  ) %>%
  ungroup()

#weekend/holiday morning peak 
join_df_wknd11_14_group <- join_df1114 %>%
        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  filter(TRIPS > 0) %>%
  group_by(grid_id) %>%
  summarize(
    bus_stop_count = n(),
    total_trips = sum(TRIPS)
  ) %>%
  ungroup()

#weekend/holiday afternoon peak 
join_df_wknd16_19_group <- join_df1619 %>%
        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%
  filter(TRIPS > 0) %>%
  group_by(grid_id) %>%
  summarize(
    bus_stop_count = n(),
    total_trips = sum(TRIPS)
  ) %>%
  ungroup()
```

To validate that our sf data frame does not contain any missing value, we used `any(is.na())` to check :

```{r}
#| code-fold: true
cat('Are there any missing value for Weekday Morning Peak?: ', any(is.na(join_df_wkd6_9_group)),'\n')
cat('Are there any missing value for Weekday Afternoon Peak?: ', any(is.na(join_df_wkd17_20_group)),'\n')
cat('Are there any missing value for Weekend/Holiday Morning Peak?: ', any(is.na(join_df_wknd11_14_group)),'\n')
cat('Are there any missing value for Weekend/Holiday Afternoon Peak?: ', any(is.na(join_df_wknd16_19_group)),'\n')
```

We have confirmed that there are **no missing values** for any of data frame.

# 3. Geovisualisation

After extracting the data, we are able to observe the number of bus stops in each grid based on the **grid_id**. We will use the `ggplot()` funcion to visualize the distribution of bus stops in the hexagon grid.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
ggplot(data= join_df_wkd6_9_group, 
       aes(x= bus_stop_count)) +
  geom_bar(aes(fill = bus_stop_count), show.legend = FALSE) +
  geom_text(stat = 'count',
           aes(label= paste0(stat(count), ', ', 
                             round(stat(count)/sum(stat(count))*100, 
                             2), '%')), vjust= -0.5, size= 2.0) +
  labs(y= 'No. of Grids', x= 'Count',
       title = "Distribution of Bus Stops in Hexagon Grid ") +
  scale_x_continuous(breaks = join_df_wkd6_9_group$bus_stop_count) +
  theme_minimal() 
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
ggplot(data= join_df_wkd17_20_group, 
       aes(x= bus_stop_count)) +
  geom_bar(aes(fill = bus_stop_count), show.legend = FALSE) +
  geom_text(stat = 'count',
           aes(label= paste0(stat(count), ', ', 
                             round(stat(count)/sum(stat(count))*100, 
                             2), '%')), vjust= -0.5, size= 2.0) +
  labs(y= 'No. of Grids', x= 'Count',
       title = "Distribution of Bus Stops in Hexagon Grid ") +
  scale_x_continuous(breaks = join_df_wkd17_20_group$bus_stop_count) +
  theme_minimal() 
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
ggplot(data= join_df_wknd11_14_group, 
       aes(x= bus_stop_count)) +
  geom_bar(aes(fill = bus_stop_count), show.legend = FALSE) +
  geom_text(stat = 'count',
           aes(label= paste0(stat(count), ', ', 
                             round(stat(count)/sum(stat(count))*100, 
                             2), '%')), vjust= -0.5, size= 2.0) +
  labs(y= 'No. of Grids', x= 'Count',
       title = "Distribution of Bus Stops in Hexagon Grid ") +
  scale_x_continuous(breaks = join_df_wknd11_14_group$bus_stop_count) +
  theme_minimal() 
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
ggplot(data= join_df_wknd16_19_group, 
       aes(x= bus_stop_count)) +
  geom_bar(aes(fill = bus_stop_count), show.legend = FALSE) +
  geom_text(stat = 'count',
           aes(label= paste0(stat(count), ', ', 
                             round(stat(count)/sum(stat(count))*100, 
                             2), '%')), vjust= -0.5, size= 2.0) +
  labs(y= 'No. of Grids', x= 'Count',
       title = "Distribution of Bus Stops in Hexagon Grid ") +
  scale_x_continuous(breaks = join_df_wknd16_19_group$bus_stop_count) +
  theme_minimal() 
```
:::

From the graphs, we noticed that the distributions based on the commuting flow at any given time frame, are **right-skewed**. In comparison, the differences between various time period are not significant. 27% of the grids contain two bus stops while 75% of the grids range between one to four bus stops.

## 3.1 Commuting flows

We will now plot the choropleth map using **tmap** and compare between `quantile` and `jenks` classification. Quantile maps try **to arrange groups so they have the same quantity**. As a result, the shading will look equally distributed in quantile types of maps. Jenks map is an optimization method for choropleth maps as it arranges each grouping so there is **less variation in each class** or shading.

In the code chuck below, we will use ***tmap*** to plot the spatial distribution of the passenger volume *(Total Trips)* based on the hexagon grid. We will use *`tmap_arrange()`* to show the plots together.

::: panel-tabset
# Quantile

```{r}
#| code-fold: true
#weekday morning peak 
plot0609 <- tm_shape(join_df_wkd6_9_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Total Trips") +
  tm_layout(main.title = "Weekday Morning Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekday afternoon peak 
plot1720 <- tm_shape(join_df_wkd17_20_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Total Trips") +
  tm_layout(main.title = "Weekday Afternoon Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekend/holiday morning peak 
plot1114 <- tm_shape(join_df_wknd11_14_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Total Trips") +
  tm_layout(main.title = "Weekend/Holiday Morning Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekend/holiday afternoon peak 
plot1619 <- tm_shape(join_df_wknd16_19_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "quantile", 
          palette = "Blues",
          title = "Total Trips") +
  tm_layout(main.title = "Weekend/Holiday Afternoon Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15,       
             position = c("left", "bottom"))

tmap_arrange(plot0609, plot1720, plot1114, plot1619, asp=2, ncol=2)
```

# Jenks

```{r}
#| code-fold: true
#weekday morning peak 
plot0609j <- tm_shape(join_df_wkd6_9_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "jenks", 
          palette = "Reds",
          title = "Total Trips") +
  tm_layout(main.title = "Weekday Morning Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekday afternoon peak 
plot1720j <- tm_shape(join_df_wkd17_20_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "jenks", 
          palette = "Reds",
          title = "Total Trips") +
  tm_layout(main.title = "Weekday Afternoon Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekend/holiday morning peak 
plot1114j <- tm_shape(join_df_wknd11_14_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "jenks", 
          palette = "Reds",
          title = "Total Trips") +
  tm_layout(main.title = "Weekend/Holiday Morning Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15, 
             position = c("left", "bottom"))

#weekend/holiday afternoon peak 
plot1619j <- tm_shape(join_df_wknd16_19_group) +
  tm_borders(alpha = 0.5) +
  tm_fill("total_trips", 
          style = "jenks", 
          palette = "Reds",
          title = "Total Trips") +
  tm_layout(main.title = "Weekend/Holiday Afternoon Peak passenger trips by Origin",
            main.title.position = "center",
            main.title.fontface = "bold",
            main.title.size = 0.6,
            legend.height = 0.3, 
            legend.width = 0.3,
            frame = TRUE) +
  tm_credits("Source: Population data from \n Department of Statistics (DOS)", 
             fontface = "italic",  
             size = 0.15,       
             position = c("left", "bottom"))

tmap_arrange(plot0609j, plot1720j, plot1114j, plot1619j, asp=2, ncol=2)

```
:::

**Observations:**

By looking at the **4 quantitle** chloropleth maps *(in blue)*, we could infer the following:

-   Passenger volume is significantly higher on Weekday than Weekends/Holidays. It ranges around 400k-550k on Weekdays and 110k-150k on Weekends/Holidays.

-   Majority of the bus stops in the Central and Southern region of Singapore have a relatively higher passenger volume compared to other regions.

![](data/images/image01.png)

-   A quick visualization from the mapview in Section 2.3.2 revealed the location in the red circle as Woodlands - Johor Bahru, Malaysia while the red rectangle is in Tanan Merah. Interestingly, as seen in the red circle, the volume have not declined regardless of time period. People are still travelling to Johor Bahru, Malaysia at any given point.

-   On the contrary, as seen in the red rectangle, the volume changes. It peaks during the Weekend/Holiday period compared to Weekdays. which could be a popular hangout for people over the weekends.

As observed in Section 3, our data are skewed to one end. Thus, it is not as ideal for us to use the quantile data classification method. We will look at the **4 jenks** chloropleth maps *(in red)*.

![](data/images/image02.png)

-   As identified earlier in the quantile map about the red rectangle at Tanan Merah, we noted the peak is only on the Weekend/Holiday Afternoon. Based on the natural grouping in the data, we are affirmed that the passenger volume towards Johor Bahru, Malaysia remains at the peak throughout the week, and throughout the day.

-   From the Jenks Classification maps, we have two new observations. From the red and blue circle, we identified that the passenger volume surge on Weekday Morning Peak hour.

-   In comparison, there are more bus stops with higher passenger volume in Weekday Morning followed by Weekend/Holiday Afternoon.

# 4. GeoSpatial Autocorrelation

In this section, we will explore the computation of Global and Local Measures of Spatial Association, with further focus on Local Indicators of Spatial Association (LISA) Analysis through the **sfdep** package. We will perform the Moran's I test which can be classified as positive, negative, and with no spatial auto-correlation. The goal is our analysis is to understand more about the passenger volume across the time period.

## 4.1 Define Neighborhood

Before we perform the Moran's I test, we would need to determine which locations are considered neighbors. As such, we will be using the ***queen method*** from the `spdep:: poly2nb()` package to compute contiguity spatial weights to identify adjacent neighbors.

::: panel-tabset
# Weekday (0600-0900)

```{r}
wm_q0609 <- poly2nb(join_df_wkd6_9_group, queen=TRUE)
summary(wm_q0609)
```

# Weekday (1700-2000)

```{r}
wm_q1720 <- poly2nb(join_df_wkd17_20_group, queen=TRUE)
summary(wm_q1720)
```

# Weekends/Holidays (1100-1400)

```{r}
wm_q1114 <- poly2nb(join_df_wknd11_14_group, queen=TRUE)
summary(wm_q1114)
```

# Weekends/Holidays (1600-1900)

```{r}
wm_q1619 <- poly2nb(join_df_wknd16_19_group, queen=TRUE)
summary(wm_q1619)
```
:::

From the summary report above, the region range from 1,483 to 1,499. On average , each area is contigious with about 4 other grids. However, there are 11/12 regions that does not have any contigious neighbors. Therefore, we would not be using Contiguity-based Spatial Weights for further analysis.

## 4.2 Deriving the centroid

Instead, we are interested in the distanced-based contiguity. To begin, we will get the coordinates of polygon centroids for each area of the commuting flows. We will be using the `st_centroid()` function to calculate the geometric center of a spatial object.

```{r}
#| code-fold: true
#weekday morning peak 
coords0609 <- st_centroid(st_geometry(join_df_wkd6_9_group))
coords0609[1]
#weekday afternoon peak 
coords1720 <- st_centroid(st_geometry(join_df_wkd17_20_group))
coords1720[1]
#weekend/holiday morning peak 
coords1114 <- st_centroid(st_geometry(join_df_wknd11_14_group))
coords1114[1]
#weekend/holiday afternoon peak 
coords1619 <- st_centroid(st_geometry(join_df_wknd16_19_group))
coords1619[1]
```

## 4.3 Determine the cut-off distance

Thereafter, we will need to determine the cut-off distance by looking at the upper bound. We will be using `knearneigh()` of **spdep** to identify the k nearest neighbors of each other. If longlat = TRUE, it computes the Euclidean distance with a lower and upper bounds by doing the following:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbors of each other by using `knearneigh()` of **spdep**.

-   Convert the knn object returned by `knearneigh()` into a neighbors list of class nb with a list of integer vectors containing neighbor region number ids by using `knn2nb()`.

-   Return the length of neighbor relationship edges by using `nbdists()` of **spdep.** The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using `unlist()`.

::: panel-tabset
# Weekday (0600-0900)

```{r}
k0609 <- knn2nb(knearneigh(coords0609, k = 1))
k0609dists <- unlist(nbdists(k0609, coords0609))
summary(k0609dists)
```

# Weekday (1700-2000)

```{r}
k1720 <- knn2nb(knearneigh(coords1720, k = 1))
k1720dists <- unlist(nbdists(k1720, coords1720))
summary(k1720dists)
```

# Weekends/Holidays (1100-1400)

```{r}
k1114 <- knn2nb(knearneigh(coords1114, k = 1))
k1114dists <- unlist(nbdists(k1114, coords1114))
summary(k1114dists)
```

# Weekends/Holidays (1600-1900)

```{r}
k1619 <- knn2nb(knearneigh(coords1619, k = 1))
k1619dists <- unlist(nbdists(k1619, coords1619))
summary(k1619dists)
```
:::

From the summary reports above, the largest first nearest neighbor distance is **4,582km** *(lowest value among the four commuting flows)*. Thus, we will use this as the upper threshold such that all units will have at least one neighbor.

## 4.4 Computing Fixed distance weight matrix

Knowing the upper threshold, we will be able to compute the fixed distance weight matrix. We will compute the distance weight matrix by using *`dnearneigh()`* as shown below.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
#weekday morning peak 
wm_d0609 <- dnearneigh(coords0609,0,4582)
wm_d0609
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
#weekday afternoon peak 
wm_d1720 <- dnearneigh(coords1720,0,4582)
wm_d1720
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
#weekend/holiday morning peak 
wm_d1114 <- dnearneigh(coords1114,0,4582)
wm_d1114
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
#weekend/holiday afternoon peak 
wm_d1619 <- dnearneigh(coords1619,0,4582)
wm_d1619
```
:::

From the output across the commuting flows, we identify an average of [153 neighbors per grid]{.underline} using the distance based weight matrix.

Next, `nb2listw()` is used to convert the nb object into spatial weights object.

```{r}
#| code-fold: true
#weekday morning peak 
wm0609_lw <- nb2listw(wm_d0609, style = 'B',zero.policy = TRUE)

#weekday afternoon peak 
wm1720_lw <- nb2listw(wm_d1720, style = 'B',zero.policy = TRUE)

#weekend/holiday morning peak 
wm1114_lw <- nb2listw(wm_d1114, style = 'B',zero.policy = TRUE)

#weekend/holiday afternoon peak 
wm1619_lw <- nb2listw(wm_d1619, style = 'B',zero.policy = TRUE)

#summary(wm0609_lw)

```

## 4.5 Computing Adaptive distance weight matrix

Alternatively, we could directly control the number of neighbors using k-nearest neighbors by using `knearneigh()` function. For our analysis, we will set the number of neighbors to **8.** *(i.e., all grids will have 8 neighbors).*

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
#weekday morning peak 
knn0609 <- knn2nb(knearneigh(coords0609, k=8))
knn0609
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
#weekday afternoon peak 
knn1720 <- knn2nb(knearneigh(coords1720, k=8))
knn1720
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
#weekend/holiday morning peak 
knn1114 <- knn2nb(knearneigh(coords1114, k=8))
knn1114
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
#weekend/holiday afternoon peak 
knn1619 <- knn2nb(knearneigh(coords1619, k=8))
knn1619
```
:::

Next, `nb2listw()` is used to convert the nb object into spatial weights object.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
#weekday morning peak 
knn0609_lw <- nb2listw(knn0609, style = 'B')
summary(knn0609_lw)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
#weekday afternoon peak 
knn1720_lw <- nb2listw(knn1720, style = 'B')
summary(knn1720_lw)
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
#weekend/holiday morning peak 
knn1114_lw <- nb2listw(knn1114, style = 'B')
summary(knn1114_lw)
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
#weekend/holiday afternoon peak 
knn1619_lw <- nb2listw(knn1619, style = 'B')
summary(knn1619_lw)
```
:::

With the spatial weights objects, we are able to plot and compare the fixed and adaptive distance-based neighbors.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
par(mfrow=c(1,2))
plot(join_df_wkd6_9_group$honeycomb_grid_wkd6_9, border="lightgrey", main="Adaptive Distance (8)")
plot(knn0609, coords0609, add=TRUE, col="red", length=0.08)
plot(join_df_wkd6_9_group$honeycomb_grid_wkd6_9, border="lightgrey", main="Fixed Distance")
plot(wm_d0609, coords0609, add=TRUE, pch = 19, cex = 0.6)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
par(mfrow=c(1,2))
plot(join_df_wkd17_20_group$honeycomb_grid_wkd17_20, border="lightgrey", main="Adaptive Distance (8)")
plot(knn1720, coords1720, add=TRUE, col="red", length=0.08)
plot(join_df_wkd17_20_group$honeycomb_grid_wkd17_20, border="lightgrey", main="Fixed Distance")
plot(wm_d1720, coords1720, add=TRUE, pch = 19, cex = 0.6)
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
par(mfrow=c(1,2))
plot(join_df_wknd11_14_group$honeycomb_grid_wknd11_14, border="lightgrey", main="Adaptive Distance (8)")
plot(knn1114, coords1114, add=TRUE, col="red", length=0.08)
plot(join_df_wknd11_14_group$honeycomb_grid_wknd11_14, border="lightgrey", main="Fixed Distance")
plot(wm_d1114, coords1114, add=TRUE, pch = 19, cex = 0.6)
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
par(mfrow=c(1,2))
plot(join_df_wknd16_19_group$honeycomb_grid_wknd16_19, border="lightgrey", main="Adaptive Distance (8)")
plot(knn1619, coords1619, add=TRUE, col="red", length=0.08)
plot(join_df_wknd16_19_group$honeycomb_grid_wknd16_19, border="lightgrey", main="Fixed Distance")
plot(wm_d1619, coords1619, add=TRUE, pch = 19, cex = 0.6)
```
:::

Due to the high volume, the graph have a high density that makes it hard to us to interpret. However, by looking at the commuting flow, we could see the changes in the neighbor links at the north regions.

By looking at the fixed and adaptive distanced-based matrics, we noticed that there is a decrease in the percentage of nonzero weight, infering that there might be grid with more neighbors.

As such, we will select **adaptive distanced-based spatial weight matrix** for our subsequent analysis.

## 4.6 Computing Global Moran's I

We will perform Moran's I statistical testing by using `moran.test()` of **spdep** on the passenger volume at hexagon level to detect cluster and/or outlier. The global Moran's I will be performed on the adaptive distance weight matrix.

Moran's I describe how features differ from the values in the study area as a whole. The Moran I statistic ranges from -1 to 1. If the Moran's I is:

-   **`positive (I>0)`**: Clustered, observations tend to be similar

-   **`negative (I<0)`**: Disperse, observations tend to be dissimilar

-   **`approximately zero`**: observations arranged randomly over space

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
moran.test(join_df_wkd6_9_group$total_trips, 
           listw=knn0609_lw, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
moran.test(join_df_wkd17_20_group$total_trips, 
           listw=knn1720_lw, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
moran.test(join_df_wknd11_14_group$total_trips, 
           listw=knn1114_lw, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
moran.test(join_df_wknd16_19_group$total_trips, 
           listw=knn1619_lw, 
           zero.policy = TRUE, 
           na.action=na.omit)
```
:::

**Interpretation of results**

Based on the all the results above, we conclude that the p-value is below the alpha value of 0.05, therefore, we have sufficient statistical evidence to **reject** the null hypothesis at 95% confidence level that the attribute is randomly distributed.

In addition, the Moran's I value is greater than 0. This shows that the observations are **clustered**, and tend to be similar to one another.

## 4.7 Computing Monte Carlo Moran's I

We will perform permutation test for Moran's statistic by using `moran.mc()` of **spdep**. A total of 1000 simulation will be performed through random assignment:

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
set.seed=123

moran.mc(join_df_wkd6_9_group$total_trips, 
         listw=knn0609_lw, 
         nsim=999,
         zero.policy = TRUE, 
         na.action=na.exclude)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
set.seed=123

moran.mc(join_df_wkd17_20_group$total_trips, 
         listw=knn1720_lw, 
         nsim=999,
         zero.policy = TRUE, 
         na.action=na.exclude)
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
set.seed=123

moran.mc(join_df_wknd11_14_group$total_trips, 
         listw=knn1114_lw, 
         nsim=999,
         zero.policy = TRUE, 
         na.action=na.exclude)
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
set.seed=123

moran.mc(join_df_wknd16_19_group$total_trips, 
         listw=knn1619_lw, 
         nsim=999,
         zero.policy = TRUE, 
         na.action=na.exclude)
```
:::

**Interpretation of results**

Based on the all the results above, we have sufficient statistical evidence to **reject** the null hypothesis at 95% confidence level. This suggests that there are some degree of clustering in the commuting flows.

# 5. Cluster and Outlier Analysis

## 5.1 Computing local Moran's I

We will perform Local Moran's I statistical testing using `localmoran()` of **spdep.** The code chunks below are used to compute local Moran's I of Passenger volume at the hexagon level *(grid_id)*.

If the Local Moran's I value is:

-   **`positive`**: Part of a cluster. Feature has neighboring features with similarly high/low attribute values

-   **`negative`**: part of an outlier. Feature has neighboring features with dissimilar values.

Before we map, we would need to compute them using `localmoran()` function of **spdep** package. Given a set of Z.Li values, it computes **Ii** , and a listw object providing neighbor weighting information for the polygon associated with the Z.Ii values.

```{r}
#| code-fold: true
fips <- order(join_df_wkd6_9_group$grid_id)
#weekday morning peak 
localMI_0609ad <- localmoran(join_df_wkd6_9_group$total_trips, knn0609_lw)
#weekday afternoon peak 
localMI_1720ad <- localmoran(join_df_wkd17_20_group$total_trips, knn1720_lw)
#weekend/holiday morning peak 
localMI_1114ad <- localmoran(join_df_wknd11_14_group$total_trips, knn1114_lw)
#weekend/holiday afternoon peak 
localMI_1619ad <- localmoran(join_df_wknd16_19_group$total_trips, knn1619_lw)
```

The code chunk below is used to compute the passenger volume at hexagon level.

::: panel-tabset
# Weekday (0600-0900)

```{r}
head(localMI_0609ad)
```

# Weekday (1700-2000)

```{r}
head(localMI_1720ad)
```

# Weekends/Holidays (1100-1400)

```{r}
head(localMI_1114ad)
```

# Weekends/Holidays (1600-1900)

```{r}
head(localMI_1619ad)
```
:::

::: {.callout-note title="Note about localmoran() " collapse="true"}
## Note about `localmoran()`

`localmoran()` returns a matrix of values whose columns are:

1.  "Ii" : the local Moran's I statistics

2.  "E.Ii" : the **expectation** of local moran statistics under the randomisation hypothesis

3.  "Var.Ii" : the **variance** of local moran statistic under the randomisation hypothesis

4.  "Z.Ii" : the **standard deviation** of local moran statistic

5.  "Pr()" : the **p-value** of local moran statistic
:::

## 5.2 Mapping the local Moran's I

Next, we will be using `cbind()` function to combine the local Moran's dataframe *(e.g., localMI_0609ad)* with our existing spatial data frame *(e.g. join_df_wkd6_9\_group)* before plotting.

```{r}
#| code-fold: true
#weekday morning peak 
join_df_wkd6_9_group.localMI_0609ad <- cbind(join_df_wkd6_9_group,localMI_0609ad) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)   #adaptive distance 

#weekday afternoon peak 

join_df_wkd17_20_group.localMI_1720ad <- cbind(join_df_wkd17_20_group,localMI_1720ad) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)   #adaptive distance 

#weekend/holiday morning peak 

join_df_wknd11_14_group.localMI_1114ad <- cbind(join_df_wknd11_14_group,localMI_1114ad) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)   #adaptive distance 

#weekend/holiday afternoon peak 

join_df_wknd16_19_group.localMI_1619ad <- cbind(join_df_wknd16_19_group,localMI_1619ad) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)   #adaptive distance 

```

### 5.2.1 Mapping Local Moran's I values and p-values 

Using the choropleth mapping function from the **tmap** package, we will do a visualization for the Local Moran's I values and its corresponding p-values.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
localMI_0609ad.map <- tm_shape(join_df_wkd6_9_group.localMI_0609ad) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

pvalue_0609ad.map <- tm_shape(join_df_wkd6_9_group.localMI_0609ad) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.3)+ 
  tm_layout(main.title = "Local Moran's I p-values Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_0609ad.map, pvalue_0609ad.map, asp = 1, ncol = 2)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
localMI_1720ad.map <- tm_shape(join_df_wkd17_20_group.localMI_1720ad) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

pvalue_1720ad.map <- tm_shape(join_df_wkd17_20_group.localMI_1720ad) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.3)+ 
  tm_layout(main.title = "Local Moran's I p-values Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_1720ad.map, pvalue_1720ad.map, asp = 1, ncol = 2)
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
localMI_1114ad.map <- tm_shape(join_df_wknd11_14_group.localMI_1114ad) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

pvalue_1114ad.map <- tm_shape(join_df_wknd11_14_group.localMI_1114ad) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.3)+ 
  tm_layout(main.title = "Local Moran's I p-values Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_1114ad.map, pvalue_1114ad.map, asp = 1, ncol = 2)
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
localMI_1619ad.map <- tm_shape(join_df_wknd16_19_group.localMI_1619ad) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

pvalue_1619ad.map <- tm_shape(join_df_wknd16_19_group.localMI_1619ad) + 
                tm_fill(col = "Pr.Ii",
                       breaks = c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
                       palette = "-Blues",
                       title = "Local Moran's I p-values") + 
                tm_borders(alpha = 0.3)+ 
  tm_layout(main.title = "Local Moran's I p-values Map",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_1619ad.map, pvalue_1619ad.map, asp = 1, ncol = 2)
```
:::

From the graphs above, we could see the gradient of the color that might not be that intuitive. Alternatively, we could look into the following section where we only retain grid that are statistically significant.

#### 5.2.1.1 Areas that are Statistically Significant

First, we will filter out all the areas that are not statistically significant (p-value \>=0.05), Then we will plot the base hexagon map and plot accordingly.

```{r}
#| code-fold: true
#weekday morning peak (Adaptive)

join_df_wkd6_9_group.localMI_0609ad_sig <- join_df_wkd6_9_group.localMI_0609ad %>%
  filter(Pr.Ii < 0.05)

base <- tm_shape(join_df_wkd6_9_group) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_0609sig_ad.map <- base + 
  tm_shape(join_df_wkd6_9_group.localMI_0609ad_sig) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n (Weekday Morning)",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE)

#weekday afternoon peak 
join_df_wkd17_20_group.localMI_1720ad_sig <- join_df_wkd17_20_group.localMI_1720ad%>%
  filter(Pr.Ii < 0.05)

base <- tm_shape(join_df_wkd17_20_group) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_1720sig_ad.map <- base + 
  tm_shape(join_df_wkd17_20_group.localMI_1720ad_sig) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n (Weekday Afternoon)",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE)

#weekends/holiday morning peak 
join_df_wknd11_14_group.localMI_1114ad_sig <- join_df_wknd11_14_group.localMI_1114ad%>%
  filter(Pr.Ii < 0.05)

base <- tm_shape(join_df_wknd11_14_group) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_1114sig_ad.map <- base + 
  tm_shape(join_df_wknd11_14_group.localMI_1114ad_sig) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n (Weekends/Holidays Morning)",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE)

#weekends/holiday afternoon peak 
join_df_wknd16_19_group.localMI_1619ad_sig <- join_df_wknd16_19_group.localMI_1619ad%>%
  filter(Pr.Ii < 0.05)

base <- tm_shape(join_df_wknd16_19_group) + 
  tm_fill(col = 'gray98') + 
  tm_borders(alpha = 0.3)

localMI_1619sig_ad.map <- base + 
  tm_shape(join_df_wknd16_19_group.localMI_1619ad_sig) +
  tm_fill(col = "Ii", 
          style = "pretty",
          title = "Local Moran I Statistics") +
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "Local Moran's I (Sig.) Map \n (Weekends/Holidays Afternoon)",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.35, 
            legend.width = 0.35,
            frame = TRUE)

tmap_arrange(localMI_0609sig_ad.map,localMI_1720sig_ad.map,
             localMI_1114sig_ad.map, localMI_1619sig_ad.map,
            ncol = 2)

```

From the Local Moran I plot, we can see that the

Once we are done with the computation, we will plot the scatterplot using the variables above.

## 5.3 Moran Scatterplot

First, we will calculate the scaled attribute and the lagged scaled attribute using the scale() function and lag.listw() function.

```{r}
#| code-fold: true
DV0609ad <- scale(join_df_wkd6_9_group.localMI_0609ad$total_trips) %>%
  as.vector 
DV1720ad <- scale(join_df_wkd17_20_group.localMI_1720ad$total_trips) %>%
  as.vector
DV1114ad <- scale(join_df_wknd11_14_group.localMI_1114ad$total_trips) %>%
  as.vector
DV1619ad <- scale(join_df_wknd16_19_group.localMI_1619ad$total_trips) %>%
  as.vector
```

we will plot the Moran scatterplot using the standardised values and moran.plot() of spdep.

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true
nci_0609 <- moran.plot(DV0609ad, knn0609_lw,
                  labels = as.character(join_df_wkd6_9_group$grid_id),
                  xlab = "Weekday Morning Peak",
                  ylab = "Spatially Lag Weekday Morning Peak")
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
nci_1720 <- moran.plot(DV1720ad, knn1720_lw,
                  labels = as.character(join_df_wkd17_20_group$grid_id),
                  xlab = "Weekday Afternoon Peak",
                  ylab = "Spatially Lag Weekday Afternoon Peak")
```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
nci_1114 <- moran.plot(DV1114ad, knn1114_lw,
                  labels = as.character(join_df_wknd11_14_group$grid_id),
                  xlab = "Weekends/Holidays Morning Peak",
                  ylab = "Spatially Lag Weekends/Holidays Morning Peak")
```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
nci_1619 <- moran.plot(DV1619ad, knn1619_lw,
                  labels = as.character(join_df_wknd16_19_group$grid_id),
                  xlab = "Weekends/Holidays Afternoon Peak",
                  ylab = "Spatially Lag Weekends/Holidays Afternoon Peak")
```
:::

## 5.4 LISA Clusters Map

::: panel-tabset
# Weekday (0600-0900)

```{r}
#| code-fold: true

#weekday morning peak 
#Step 1
quadrant <- vector(mode = 'numeric', length = nrow(localMI_0609ad))
#Step 2
join_df_wkd6_9_group$lag <- lag.listw(knn0609_lw,join_df_wkd6_9_group$total_trips)
DV_0609 <- join_df_wkd6_9_group$lag - mean(join_df_wkd6_9_group$lag)
#Step 3
LM_I_0609 <- localMI_0609ad[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant[DV_0609 <0 & LM_I_0609>0] <- 1 #low-low
quadrant[DV_0609 >0 & LM_I_0609<0] <- 2 #high-low
quadrant[DV_0609 <0 & LM_I_0609<0] <- 3 #low-high
quadrant[DV_0609 >0 & LM_I_0609>0] <- 4 #high-high
#Step 6
quadrant[localMI_0609ad[,5]>signif] <- 0
```

```{r}
#| code-fold: true
#weekday morning peak 
#Assign each region  to its respective quardrant
join_df_wkd6_9_group.localMI_0609ad$quadrant <- quadrant

#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_0609 <- tm_shape(join_df_wkd6_9_group.localMI_0609ad) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n (Weekday Morning) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```

# Weekday (1700-2000)

```{r}
#| code-fold: true
#weekday afternoon peak 
#Step 1
quadrant <- vector(mode = 'numeric', length = nrow(localMI_1720ad))
#Step 2
join_df_wkd17_20_group$lag <- lag.listw(knn1720_lw,join_df_wkd17_20_group$total_trips)
DV_1720 <- join_df_wkd17_20_group$lag - mean(join_df_wkd17_20_group$lag)
#Step 3
LM_I_1720 <- localMI_1720ad[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant[DV_1720 <0 & LM_I_1720>0] <- 1 #low-low
quadrant[DV_1720 >0 & LM_I_1720<0] <- 2 #high-low
quadrant[DV_1720 <0 & LM_I_1720<0] <- 3 #low-high
quadrant[DV_1720 >0 & LM_I_1720>0] <- 4 #high-high
#Step 6
quadrant[localMI_1720ad[,5]>signif] <- 0
```

```{r}
#| code-fold: true
#weekday morning peak 
#Assign each region  to its respective quardrant
join_df_wkd17_20_group.localMI_1720ad$quadrant <- quadrant

#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_1720 <- tm_shape(join_df_wkd17_20_group.localMI_1720ad) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n (Weekday Afternoon) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

```

# Weekends/Holidays (1100-1400)

```{r}
#| code-fold: true
#weekends/holidays morning peak 
#Step 1
quadrant <- vector(mode = 'numeric', length = nrow(localMI_1114ad))
#Step 2
join_df_wknd11_14_group$lag <- lag.listw(knn1114_lw,join_df_wknd11_14_group$total_trips)
DV_1114<- join_df_wknd11_14_group$lag - mean(join_df_wknd11_14_group$lag)
#Step 3
LM_I_1114 <- localMI_1114ad[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant[DV_1114 <0 & LM_I_1114>0] <- 1 #low-low
quadrant[DV_1114 >0 & LM_I_1114<0] <- 2 #high-low
quadrant[DV_1114 <0 & LM_I_1114<0] <- 3 #low-high
quadrant[DV_1114 >0 & LM_I_1114>0] <- 4 #high-high
#Step 6
quadrant[localMI_1114ad[,5]>signif] <- 0
```

```{r}
#| code-fold: true
#weekends/holiday morning peak 
#Assign each region  to its respective quardrant
join_df_wknd11_14_group.localMI_1114ad$quadrant <- quadrant

#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_1114 <- tm_shape(join_df_wknd11_14_group.localMI_1114ad) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n (Weekends/Holidays Morning) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)

```

# Weekends/Holidays (1600-1900)

```{r}
#| code-fold: true
#weekends/holidays afternoon peak 
#Step 1
quadrant <- vector(mode = 'numeric', length = nrow(localMI_1619ad))
#Step 2
join_df_wknd16_19_group$lag <- lag.listw(knn1619_lw,join_df_wknd16_19_group$total_trips)
DV_1619<- join_df_wknd16_19_group$lag - mean(join_df_wknd16_19_group$lag)
#Step 3
LM_I_1619 <- localMI_1619ad[,1] 
#Step 4
signif <- 0.05
#Step 5
quadrant[DV_1619 <0 & LM_I_1619>0] <- 1 #low-low
quadrant[DV_1619 >0 & LM_I_1619<0] <- 2 #high-low
quadrant[DV_1619 <0 & LM_I_1619<0] <- 3 #low-high
quadrant[DV_1619 >0 & LM_I_1619>0] <- 4 #high-high
#Step 6
quadrant[localMI_1619ad[,5]>signif] <- 0
```

```{r}
#| code-fold: true
#weekends/holiday morning peak 
#Assign each region  to its respective quardrant
join_df_wknd16_19_group.localMI_1619ad$quadrant <- quadrant

#Set the colours--one for each quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c") 

clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap_1619 <- tm_shape(join_df_wknd16_19_group.localMI_1619ad) + 
  tm_fill(col = "quadrant",
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1])  + 
  tm_borders(alpha = 0.3) + 
  tm_layout(main.title = "LISA Cluster Map \n (Weekends/Holidays Morning) ",
            main.title.size = 1,
            main.title.position = "center",
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE)
```
:::

```{r}
#| code-fold: true
tmap_arrange(LISAmap_0609, LISAmap_1720,
  LISAmap_1114, LISAmap_1619, ncol =2)
```

```{r}
#| code-fold: true
tmap_arrange(localMI_0609sig_ad.map, LISAmap_0609, 
             localMI_1720sig_ad.map, LISAmap_1720,
             ncol =2)
```

```{r}
#| code-fold: true
tmap_arrange(localMI_1114sig_ad.map, LISAmap_1114, 
             localMI_1619sig_ad.map, LISAmap_1619, 
             ncol =2)

```
