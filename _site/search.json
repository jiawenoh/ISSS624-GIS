[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, tidyverse , and knitr packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-queen-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-queen-contiguity-based-neighbors",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.1 Computing (QUEEN) contiguity based neighbors",
    "text": "3.1 Computing (QUEEN) contiguity based neighbors\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\n1 most connected region with 11 neighbors, and\n2 least connected regions with only 1 neighbor.\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. E.g., to see the neighbors of the first polygon in the object, we could use the following code:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nFrom the output, we observed that polygon 1 have 5 neighbors. The respective polygons ID are stored in the hunan Spatial Polygons Data Frame Class.\nTo retrieve the country name of Polygon ID = 1, we can use the following code:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output shows that Polygon ID = 1 is Anxiang country. To know more about the five neighboring polygons that we have identified with, the below code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nSimilarly, we are able to retrieve the GDPPC of these five countries by using the code chunk below:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nAdditionally, we can display the complete weight matrix by using str() . For the purpose of this exercise, we will add [0:10] to display the first 10 list instead of the full 88.\n\nstr(wm_q[0:10])\n\nList of 10\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-rook-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-rook-contiguity-based-neighbors",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.2 Creating (ROOK) contiguity based neighbors",
    "text": "3.2 Creating (ROOK) contiguity based neighbors\nThe code chunk below will be used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\nSimilar to section 3.1 in terms of area units and least connected regions.\nDiffers in the most connected area as Rook shows 10 neighbors whereas Queen shows 11 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#visualising-contiguity-weights",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.3 Visualising contiguity weights",
    "text": "3.3 Visualising contiguity weights\nWe will be using sf package to get the latitude and longitude of the polygon centroids which allow us to take a point and display a line to each neighboring point. To do so, we would require the coordinates in a separate data frame, and apply a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length.\nOur input vector will be geometry column of us.bound while our function will be st_centroid. Additionally, we will be using map_dbl variation of map from the purrr package.\nTo get our longitude value, we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1 which allows us to get the first value in each centroid and the longitude.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nSimilarly, we use the same approach to get latitude. However, we will replace 1 with 2.\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWith longitude and latitude, we can combine them through cbind() to put longitude and latitude into the same object and use head() to check the first few observations.\n\ncoords <- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-contiguity-based-neighbors-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-contiguity-based-neighbors-map",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.4 Plotting Contiguity based neighbors map",
    "text": "3.4 Plotting Contiguity based neighbors map\nWe will be plotting the contiguity based neighbors map for Queen, and Rock. Ideally, we are able to plot individually, or combined them together.\n\nQueenRookQueen and Rook\n\n\n\n\nShow the code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\nShow the code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\") \n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-leg-with-row-standarized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-leg-with-row-standarized-weights",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.1 Spatial leg with row-standarized weights",
    "text": "7.1 Spatial leg with row-standarized weights\n\nProcessOutput\n\n\nStep 1: Compute average neighbor GDPP value for each polygon. Often, these values are referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nStep 2: Append spatially lag GDPPC values onto hunan sf data frame\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nStep 3: Verify data frame\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\n\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-lag-as-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-lag-as-sum-of-neighboring-values",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.2 Spatial lag as sum of neighboring values",
    "text": "7.2 Spatial lag as sum of neighboring values\n\nProcessOutput\n\n\nTo begin, we can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw() function to explicitly assign these weights.\nStep 1: apply lapply() function to assign a value of 1 for each neighbor\nStep 2: apply nb2listw() function to explicitly assign these weights.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nStep 3: use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nStep 4: examine the result\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nStep 5: Append the lag_sum GDPPC into hunan sf data frame\n\nhunan <- left_join(hunan, lag.res)\n\n\n\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-average",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.3 Spatial window average",
    "text": "7.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element.\n\nProcessOutput\n\n\nStep 1: add diagonal element to the neighbor list by using include.self() from spdep\n\nwm_qs <- include.self(wm_q)\n\nStep 2: Check neighbor list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nStep 3: Obtain weights with nb2listw()\n\nwm_qs <- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nStep 4: create lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gpdpc <- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nStep 5: convert lag variable listw object into a dataframe by using as.data.frame()\n\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nStep 6: append lag_window_avg GDPPC values onto hunan sf data frame using left_join()\n\nhunan <- left_join(hunan, lag_wm_qs.res)\n\nStep 7: compare values of lag GDPPC and Spatial window average by using kable() of Knitr package\n\nhunan %>%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\nPlot lap_gdppc and w_ave_gdppc maps by using qtm() of tmap package\n\n\nShow the code\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-sum",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.4 Spatial window sum",
    "text": "7.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row- standardized weights.\n\nProcessOutput\n\n\nStep 1: add diagonal element to the neighbor list by using include.self() from spdep\n\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nStep 2: Assign binary weights to the neighbor structure that includes the diagonal element\n\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nStep 3: Explicitly assign weight values by using nb2listw() and glist()\n\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nStep 4: compute lag variable with lag.listw()\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nStep 6: convert lag variable listw object into a dataframe by using as.data.frame()\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nStep 7: append w_sum GDPPC values into hunan sf data frame by using left_join()\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nStep 8: compare values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\nPlot lap_sum GDPPC and w_sum_gdppc maps by using qtm() of tmap package\n\n\nShow the code\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in.\n\n\n\nAfter joining, we will do a quick visualization. We will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012.\n\n\nShow the code\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#computing-contiguity-spatial-weights",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.1 Computing Contiguity Spatial Weights",
    "text": "2.1 Computing Contiguity Spatial Weights\nTo begin with, we are require to construct a spatial weights of the study area. The spatial weights is used to define the neighborhood relationships between the geographical units (i.e. county) in the study area. We will be using poly2nb() of spdep package to compute QUEEN contiguity weight matrices for the study area.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\n1 most connected region with 11 neighbors, and\n2 least connected regions with only 1 neighbor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#row-standardised-weights-matrix",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.2 Row-standardised weights matrix",
    "text": "2.2 Row-standardised weights matrix\nNext, we would need to assign weights to each neighboring polygon. Weights are assigned based on the fraction of 1/#no.of neighbors to each neighboring country then summing the weighted income values.\nFor the example below, we will used style = ‘W’ option (note: there are robust options available). By adding ’Zero.police = TRUE’, we are allowing list of non-neighbors.\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote about nb2listw()\n\n\n\n\n\nnb2listw() has two major arguments, namely style and zero.policy.\nThere are 6 Styles, namely:\n\n“W” : row standardize (sum over all links to n)\n“B” : basic binary coding\n“C” : globally standardised (sum over all links to n)\n“U” : is equal to C divided by the number of neighbors (sum over all links to unity)\n“minmax” : the min, and max\n“S” : variance-stabilizing coding scheme\n\nThe default setting for zero.policy:\n\n‘NULL’ : (default), uses global option value\n‘TRUE’ : permit the weights list to be formed with zero-length weights vectors\n‘FALSE’ : stop with error for any empty neighbors sets\n\nRefer here for more information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#morans-i-statistics-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#morans-i-statistics-test",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.3 Moran’s I Statistics test",
    "text": "2.3 Moran’s I Statistics test\nThere are two tests that we could perform. In this section, we will cover the Moran’s I test. We will be using moran.test() of spdep to perform the statistical test.\n\nMoran’s I TestMonte Carlo Moran’s IVisualisation\n\n\nWe will perform Moran’s I statistical testing using moran.test() of spdep:\n\n\nShow the code\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nAs observed, we can reject the null hypothesis (Ho) as the p-value is smaller than the alpha value.\n\n\nWe will perform permutation test for Moran’s statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed:\n\n\nShow the code\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nAs observed, we can reject the null hypothesis (Ho) as the p-value is smaller than the alpha value.\n\n\nWe will be examining the simulated Moran’s I test statistic by plotting the distribution of the statistical values through a histogram:\n\n\nShow the code\n#print mean\ncat('The mean is:', mean(bperm$res[1:999]),'\\n')\n\n\nThe mean is: -0.01504572 \n\n\nShow the code\n#print variance\ncat('The variance is:', var(bperm$res[1:999]), '\\n')\n\n\nThe variance is: 0.004371574 \n\n\nShow the code\n#print summary\ncat('Summary Report\\n')\n\n\nSummary Report\n\n\nShow the code\nsummary(bperm$res[1:999])\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\nShow the code\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#gearys-statistics-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#gearys-statistics-test",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.4 Geary’s Statistics Test",
    "text": "2.4 Geary’s Statistics Test\nIn this section, we will cover the Geary’s C test. We will be using geary.test() of spdep to perform the statistical test.\n\nGeary’s C TestMonte Carlo Geary’s CVisualisation\n\n\nWe will perform Geary’s C statistical testing using geary.test() of spdep:\n\n\nShow the code\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\nWe will perform permutation test for Geary’s statistic by using geary.mc() of spdep. A total of 1000 simulation will be performed:\n\n\nShow the code\nset.seed(1234)\ngperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\ngperm\n\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nWe will be examining the simulated Geary’s C test statistic by plotting the distribution of the statistical values through a histogram:\n\n\nShow the code\n#print mean\ncat('The mean is:', mean(gperm$res[1:999]),'\\n')\n\n\nThe mean is: 1.004402 \n\n\nShow the code\n#print variance\ncat('The variance is:', var(gperm$res[1:999]), '\\n')\n\n\nThe variance is: 0.007436493 \n\n\nShow the code\n#print summary\ncat('Summary Report\\n')\n\n\nSummary Report\n\n\nShow the code\nsummary(gperm$res[1:999])\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\n\nShow the code\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-morans-i-correlogram",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "3.1 Compute Moran’s I correlogram",
    "text": "3.1 Compute Moran’s I correlogram\nThe global spatial autocorrelation used in Moran’s I. For the graph, we will use plot() of base graph.\n\n\nShow the code\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nTo get a better interpretation of the output, we can examine the full analysis by printing the results.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-gearys-c-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-gearys-c-correlogram",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "3.2 Compute Geary’s C correlogram",
    "text": "3.2 Compute Geary’s C correlogram\nThe global spatial autocorrelation used in Geary’s C. For the graph, we will use plot() of base graph.\n\n\nShow the code\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nTo get a better analysis,\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nIn this section, the following data will be imported into R through st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL , a polygon feature layer in ESRI shapefile format\nCyclingPath , a line feature layer in ESRI shapefile format, and\nPreSchool , a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() of sf package to import MP14_SUBZONE_WEB_PL:\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nIt can be observed that there are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems.\n\n\n\nThe code chunk below uses st_read() of sf package to import CyclingPath shapefile:\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nIt can be observed that there are a total of 2,558 features and 2 fields in cyclingpath linestring feature data frame. It is in svy21 projected coordinates systems.\n\n\n\nThe code chunk below will be used to import the kml (pre-schools-location-kml) into R:\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nIt can be observed that there are a total of 2,290 features and 2 fields in preschool point feature data frame. It is a wgs84 coordinates systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.1 Working with st_geometry()",
    "text": "2.1 Working with st_geometry()\nBy using mpsz$geom or mpsz[[1]], we can retrieve the geometry list-column which only display basic information of the feature class, such as type of geometry, geographic extent of the features and the coordinate system of the data.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.2 Working with glimpse ()",
    "text": "2.2 Working with glimpse ()\nBy using glimpse() of dplyr, we are able to learn more about the associated attribution information in the data frame. It reveals the data type of each fields (e.g., FMEL-UPD_D is in data data type, and X_ADDR is a double-precision values)\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.3 Working with head()",
    "text": "2.3 Working with head()\nInstead of printing the complete information, head() allow users to select the numbers of record to display (i.e., the n argument)\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "4.1 Assigning EPSG code to a simple feature data frame",
    "text": "4.1 Assigning EPSG code to a simple feature data frame\nIn the code chunk below, it illustrates the coordinate system of mpsz simple feature data frame by using st_crs() of sf package:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAs seen from the result, the EPSG code is inaccurate. Instead of showing 3414 (svg21), it displays 9001 (last row). This is a common issue that could happen in the process of importing geospatial data into R. The coordinate system of the source data could be missing or wrongly assigned.\nIn order to rectify the EPSG code, we will use the st_set_crs() of sf package:\n\nmpsz3414 <- st_transform(mpsz, 3414)\n\nTo validate, we will used the code chunk below:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-project-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-project-of-preschool-from-wgs84-to-svy21",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "4.2 Transforming the project of preschool from wgs84 to svy21",
    "text": "4.2 Transforming the project of preschool from wgs84 to svy21\nNotably, it is common for us to transform original data from geographic coordinate system to projected coordinate system as the geographic coordinate system is not appropriate if the analysis requires distance and/or area measurements.\nWe performed the project transformation by using the code chunk below:\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)\n\nTo display the first 5 geometries and content of the preschool3414 data frame, we will use head():\n\nhead(preschool3414, n=5)\n\nSimple feature collection with 5 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 24821.92 ymin: 31299.16 xmax: 28844.56 ymax: 46303.16\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n   Name\n1 kml_1\n2 kml_2\n3 kml_3\n4 kml_4\n5 kml_5\n                                                                                                                                                                                                                                                                                                                                                                                                Description\n1           <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S COVE PRESCHOOL PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9390</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>498CC9FE48CC94D4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n2                    <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S COVE PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT8675</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>22877550804213FD</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n3       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S VINEYARD PRESCHOOL PTE. LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9308</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>B2FE90E44AD494E3</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n4 <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDTIME CARE & DEVELOPMENT CENTRE PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9122</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>1384CDC0D14B76A1</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n5                               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILTERN HOUSE</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT2070</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>FB24EAA6E73B2723</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n                       geometry\n1 POINT Z (25089.46 31299.16 0)\n2 POINT Z (27189.07 32792.54 0)\n3 POINT Z (28844.56 36773.76 0)\n4 POINT Z (24821.92 46303.16 0)\n5 POINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "5.1 Importing the aspatial data",
    "text": "5.1 Importing the aspatial data\nFor the purpose of the exercise, we will be using the Singapore listing (listings.csv) as retrieved from AirBnb.\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nTo ensure data accuracy, we will check if the data file have been imported correctly. The code chunk below uses list() of Base R instead of glimpse().\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    <dbl> <chr>       <dbl> <chr>     <chr>               <chr>            <dbl>\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude <dbl>, room_type <chr>, price <dbl>,\n#   minimum_nights <dbl>, number_of_reviews <dbl>, last_review <date>,\n#   reviews_per_month <dbl>, calculated_host_listings_count <dbl>,\n#   availability_365 <dbl>, number_of_reviews_ltm <dbl>, license <chr>\n\n\nObservations:\n\nTibble data frame consists of 3,483 rows and 18 columns\nUseful fields for our analysis : latitude and longitude (note: decimal degree format)\n\nAssumption:\n\nData is in wgs84 geographic coordinate system"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "5.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "5.2 Creating a simple feature data frame from an aspatial data frame\nIn the code chunk below, we will be using st_as_sf() of sf package to convert listing data frame into a simple feature data frame:\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\ncoords : to provide x-coordinates, y-coordinates\ncrs : to provide the coordinates system in EPSG format.\nEPSG: 4326 is wgs84 Geographic Coordinate System\nEPSG : 3414 is Singapore SVY21 Projected Coordinate System.\nFor more information, do refer to epsg.io\n\n\nTo examine the content of our newly created simple feature data frame:\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             <dbl> 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           <chr> \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        <dbl> 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      <chr> \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            <chr> \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  <chr> \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 <dbl> 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              <dbl> 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    <date> 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              <dbl> 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count <dbl> 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               <dbl> 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        <chr> NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       <POINT [m]> POINT (41972.5 36390.05), POINT (…\n\n\nObservation:\n\nInstead of longitude and latitude, a new column called geometry has been added into the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "6.1 Buffering",
    "text": "6.1 Buffering\nThe scenario: The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path.\nThe task: To determine the extend of the land need to be acquired and their total area.\nThe solution:\nIn the code chunk below, we will be using st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThen, we calculate the area of the buffers:\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nLastly, we use sum() of Base R to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "6.2 Point-in-polygon count",
    "text": "6.2 Point-in-polygon count\nThe scenario: A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\n\n\n\n\n\n\n\nWarning\n\n\n\nBe careful and do not be confuse with st_intersection() !\n\n\nWe can check the summary statistics of the newly derieved Presch Count Field by using summary() as shown in the code chunk below:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below:\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe solution:\nStep 1: Use st_area() of sf package to derive the area of each planning subzone\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\nStep 2: Apply mutate() of dplyr package to compute the density\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-histogram",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "7.1 Plotting Histogram",
    "text": "7.1 Plotting Histogram\nTo observe the distribution of PreSch Density, a histogram is insightful. We can used hist() of R graphics or ggplot2 to plot.\n\n7.1.1 Histogram using hist()\n\n\nShow the code\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nDespite the easy syntax, the output is far from ideal as it limits further customization.\n\n\n7.1.2 Histogram using ggplot2()\n\n\nShow the code\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-scatterplot",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "7.2 Plotting Scatterplot",
    "text": "7.2 Plotting Scatterplot\nTo observe the relationship between Pre-school Density and Pre-school count, a scatterplot could be ideal.\n\n\nShow the code\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf , tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNote: readr, tidyr, and dplyr are part of tidyverse package\n\n\n\nIn this section, the following data will be imported into R through st_read() of sf package to create the choropleth map:\n\nMP14_SUBZONE_WEB_PL, in ESRI shapefile format, retrieved from data.gov.sg\nrespopagsex2010to2020.csv - Singapore Residents by Planning Area/Subzone, Age Group, Sex, and Type of Dwelling, June 2011-2020, retrieved from Department of Statistics, Singapore.\n\n\n\nWe will be using st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n#to examine the content\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nWe will be using read_csv() function of readr package to import respopagsex2010to2020.csv into R and save the file as a dataframe called popdata.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore we prepared for a thematic map, we would need to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by(), and select() of dplyr package\n\n\n\nShow the code\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nAfter the transformation, we will need to convert the values in PA and SZ fields to uppercase to standardize the fields. PA and SZ fields are made up of upper-and lowercase while SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nThereafter, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone (e.g. SUBZONE_N and SZ as the common identifier)\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nBy using the code chunk below, we can write a .rds file to save data into R data format.\n\nwrite_rds(mpsz_pop2020, \"data/aspatial/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-choropleth-map-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-choropleth-map-using-qtm",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.1 Plot Choropleth map using qtm()",
    "text": "2.1 Plot Choropleth map using qtm()\nqtm() provides the quickest way to draw a choropleth map. It is concise and provides a good default visualization as seen in the code chunk below.\n\n\nShow the code\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\nLearning points:\n\nTmap_mode()\n\n“Plot” is used to produce static map.\nView” is used to produce interactive mode\n\nfill argument is used to map the attribute (i.e., Dependency)\nHard to control the aesthetics of individual layers"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-using-tmaps-elements",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.2 Plot using tmap’s elements",
    "text": "2.2 Plot using tmap’s elements\nAlthough we are able to plot quickly and easily through qtm(), we are not able to draw a high quality cartographic choropleth map. As seen in the code chunk below, tmap’s drawing elements are used to add area patterns or graduated colors.\n\n2.2.1 Drawing a base map\nStep 1: To begin building the block of tmap, we will used tm_shape() to define the input data and tm_polygons() to draw the planning subzone polygons.\n\n\nShow the code\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n2.2.2 Use tm_polygons()\nStep 2: To show the geographical distribution of a selected variable by planning subzone, we will assign the target variable such as Dependency to tm_polygons(). Note: default color is Yl0rRd of ColorBrewer. By default, missing value will be shaded in grey.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n2.2.3 Use tm_fill() and tm_border()\nStep 2: Instead of using tm_polygons() in section 2.2.2, tm_fill() could be used as well. Notably, tm_polygons() is a wraper of tm_fill() and tm_borders(). tm_fill() shades the polygons by default colour scheme whereas tm_borders() add the borders of the shapefile.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\nTo add boundary to the planning subzone, tm_borders() will be used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nLearning Points:\n\n‘alpha’ is used to define transparency (range from 0 to 1) with 1 as default (non-transparent)\n‘col’ refers to border color\n‘lwd’ refers to border line width. Default as 1.\n‘lty’ refers to border line type. Default as solid.\n\n\n\n2.2.4 Final Choropleth Map\nStep 3: After adding the base map, planning subzone, colors, borders, the code chunk below reveals the finalized output with functional choropleth map.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.3 Data Classification Methods of tmap",
    "text": "2.3 Data Classification Methods of tmap\ntmap provides a total of 10 data classifications methods, namely- fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. To define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.3.1 Built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nBy changing the style, the distribution will look different. The code chunk below used equal data classification method.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nIn comparison, quantile method is evenly distributed. In addition, we observed that by increasing the number of classes, the graduated colors become more distinct.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.3.2 Custome Break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Thus, our breaks vector is c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\nWe will be able to plot the choropleth map by using the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#color-scheme",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.4 Color Scheme",
    "text": "2.4 Color Scheme\ntmap supports color ramps either defined by the user or a set of predefined color ramps from the RColorBrewer package.\n\n2.4.1 RColorBrewer Package\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n- : reverse the color shading."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layouts",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.5 Map Layouts",
    "text": "2.5 Map Layouts\nAs covered in previous section, the palette and break-points could affect how the map looks. Moreover, the combination of all map elements such as objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios create a cohesive map.\n\n2.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.5.2 Map Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style(). We will be using the classic style for the example below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n2.5.3 Cartographic Furniture\ntmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines. tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map in the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n2.5.3.1. Reset Default Style\nIf needed, the code chunk below helps to reset the default style.\nOther available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#facet-maps",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.6 Facet Maps",
    "text": "2.6 Facet Maps\nMaps could be arrange side-by-side into multiple small maps, stacked vertically or horizontally. It enable the visualization of how spatial relationships changes with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.6.1 Assign multiple values\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill() :\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\nLikewise, we could assign multiple values to at least one of the aesthetic arguments and highlight in different color.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n2.6.2 Group-by variable in tm_facets()\nMultiple small choropleth maps are created by using tm_facets() as seen in the code below:\n\n\nShow the code\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.6.3 Multiple stand-alone maps with tmap_arrange()\nMultiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange() as seen in the code below:\n\n\nShow the code\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "2.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating multiple choropleth map, we can use selection function to map spatial objections meeting the selection criterion.\n\n\nShow the code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624 Applied Geospatial Analytics",
    "section": "",
    "text": "Welcome to my learning journey in ISSS624 Applied Geospatial Analytics . In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The code chunk below load the following packages:\n\ntmap : for thematic mapping\nsf : for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)\n\n\n\n\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus <- read_csv(\"data/origin_destination_bus_202308.csv\")\n\nA quick check of odbus tibble data frame shows that the value in ORIGIN_PT_CODE.\n\nodbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)\n\nodbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\nFor the purpose of this exercise, we will extract commuting flows on weekday between 7 to 9 o’clock.\n\norigtrip_7_9 <- odbus %>%\n  filter(DAY_TYPE == \"WEEKDAY\") %>%\n  filter(TIME_PER_HOUR >= 7 &\n           TIME_PER_HOUR <= 9 ) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  ungroup()\n\nTwo geospatial data will be used in this exercise, they are:\n\nbusstop <- st_read(dsn = 'data', layer = 'BusStop') %>%\n  st_transform(crs= 3414)\n\n\nmpsz <- st_read(dsn = 'data', layer = 'MPSZ-2019') %>%\n  st_transform(crs= 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/In-class_Ex/In-class_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in.\n\n\n\nAfter joining, we will do a quick visualization. We will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012.\n\n\nShow the code\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-append-local-morans-i-with-spdf",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-append-local-morans-i-with-spdf",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 1: Append Local Moran’s I with SPDF",
    "text": "Step 1: Append Local Moran’s I with SPDF\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-map-local-morans-i-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-map-local-morans-i-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 2: Map local Moran’s I values",
    "text": "Step 2: Map local Moran’s I values\nUsing choropleth mapping function of tmap package, we can plot the local Moran’s I values:\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-map-local-morans-i-p-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-map-local-morans-i-p-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 3: Map local Moran’s I p-values",
    "text": "Step 3: Map local Moran’s I p-values\nAs seen above, Ii contains both positive and negative values. Thus, it is useful for us to consider the p-values for each values.\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-optional-map-both-local-morans-i-values-and-p-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-optional-map-both-local-morans-i-values-and-p-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 4 (Optional) : Map both local Moran’s I values and p-values",
    "text": "Step 4 (Optional) : Map both local Moran’s I values and p-values\nFor effective interpretation, we can plot both I-values and corresponding p-values next to one another.\n\n\nShow the code\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-vectorize",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-vectorize",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 1: Vectorize",
    "text": "Step 1: Vectorize\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-derive-spatially-lagged-variable-of-interest-and-centers-it-around-its-mean",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-derive-spatially-lagged-variable-of-interest-and-centers-it-around-its-mean",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 2: Derive Spatially lagged variable of interest and centers it around its mean",
    "text": "Step 2: Derive Spatially lagged variable of interest and centers it around its mean\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-center-the-local-morans-around-the-mean",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-center-the-local-morans-around-the-mean",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 3: Center the local Moran’s around the mean",
    "text": "Step 3: Center the local Moran’s around the mean\n\nLM_I <- localMI[,1] - mean(localMI[,1])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-set-statistical-significance-level-for-the-local-moran",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-set-statistical-significance-level-for-the-local-moran",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 4: Set statistical significance level for the local Moran",
    "text": "Step 4: Set statistical significance level for the local Moran\n\nsignif <- 0.05"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-5-define-the-quadrants",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-5-define-the-quadrants",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 5: Define the quadrants",
    "text": "Step 5: Define the quadrants\n1 = low-low 2 = low - high 3 = high - low 4 = high - high\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-6-place-non-significant-moran-in-category-0",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-6-place-non-significant-moran-in-category-0",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 6: Place non-significant Moran in Category 0",
    "text": "Step 6: Place non-significant Moran in Category 0\n\nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#final-output",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#final-output",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Final Output:",
    "text": "Final Output:\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#deriving-the-centriod",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#deriving-the-centriod",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.1 Deriving the centriod",
    "text": "1.1 Deriving the centriod\nBefore making our connectivity graph, we will need to associate each polygon. We will use a mapping function to get the longitude, latitude and thereafter, combine them together.\n\n#get longitude\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n#get latitude\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n#combine\ncoords <- cbind(longitude, latitude)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#determine-the-cut-off-distance",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.2 Determine the cut-off distance",
    "text": "1.2 Determine the cut-off distance\nWe need to determine the upper list for distance band by :\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n\nShow the code\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nAs seen above, the max distance is 61.79km. We can infer that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-fixed-distance-weight-matrix",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.3 Compute fixed distance weight matrix",
    "text": "1.3 Compute fixed distance weight matrix\nWe will compute the distance weight matrix by using dnearneigh():\n\n\nShow the code\n#compute distance weight matrix \nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-adaptive-distance-weight-matrix",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.4 Compute adaptive distance weight matrix",
    "text": "1.4 Compute adaptive distance weight matrix\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#gi-statistics-using-fixed-distance",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Gi Statistics using fixed distance",
    "text": "Gi Statistics using fixed distance\nNotably, the output of localG() is a vector of G or Gstar values, with attributes gstari set to TRUE or FALSE. The Gi stats represents the z-score where greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\n\n\nShow the code\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed \n\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below by converting the output vector (gi.fixed) into r matrix object by using as.matrix(). Then, cbind() to join hunan data and gi.fixed matrix to produce a new Spatial Polygon Data Frame called hunan.gi.\nLastly, it will be rename to gstat_fixed by using rename().\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#fixed-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#fixed-distance-weights",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "fixed distance weights",
    "text": "fixed distance weights\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#adaptive-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#adaptive-distance-weights",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "adaptive distance weights",
    "text": "adaptive distance weights\n\n\nShow the code\n# compute the Gi value \nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The code chunk below load the following packages:\n\ntmap : for thematic mapping\nsf : for geospatial data handling\nsfdep : for spatial dependence for Simple Features\ntidyverse: for non-spatial data handling\nknitr : for dynamic report generation\nplotly : for creating interactive graphs\n\n\npacman::p_load(tmap, sf, sfdep, tidyverse, knitr,plotly)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 25th Nov 2023. They are :\n\nHunan , a geospatial data set in ESRI shapefile format, and\nHunan_2012.csv, an attribute data set in csv format\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/In-class_Ex/In-class_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will performed a left_join() with the aid of dplyr package.\n\nhunan_GDPPC <- left_join(hunan,hunan2012) %>%\n    select(1:4,7,15)\n\n\n\n\nWe will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012 as a form of quick visualization.\n\n\nShow the code\nbasemap <- tm_shape(hunan_GDPPC) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n \ngdppc <- qtm(hunan_GDPPC, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nQueen method is used to derive the contiguity weights:\n\nwm_q <- hunan_GDPPC %>%\n  mutate (nb = st_contiguity(geometry),\n          wt = st_weights(nb, \n                          style = \"W\"),\n          .before = 1)\n\n\n\n\nIn the code chunk below, we will compute local Moran’s I test.\n\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before =1) %>%\n  unnest(local_moran) #to unnest individual columns"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "title": "In-class Exercise 2",
    "section": "1. Importing the data",
    "text": "1. Importing the data\nWe will be using the Hunan_GDPPC data for this exercise.\n\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#create-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#create-a-time-series-cube",
    "title": "In-class Exercise 2",
    "section": "2. Create a time series cube",
    "text": "2. Create a time series cube\nTo get the concept of spatio-temporal cube, we will be using the spacetime() of sfdep to create a spacetime cube.\n\nGDPPC_st <- spacetime(GDPPC, hunan, \n                       .loc_col = \"County\",\n                       .time_col = \"Year\")\n\nTo confirm if it is spacetime cube, we can check through the following code by using is_spacetime_cube() of sfdep package:\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#compute-gi",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#compute-gi",
    "title": "In-class Exercise 2",
    "section": "3. Compute Gi*",
    "text": "3. Compute Gi*\n\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>% #must-do this first to activate \n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb,geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\nWe can use the new columns to manually calculate the local Gi*. We can do so by grouping by year and using local_gstar_perm() of spdep. Thereafter, we will use unnest() to unnest gi_star column of the newly created gi_starts data frame.\n\ngi_stars <- GDPPC_nb %>%\n  group_by(Year) %>%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %>%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mann-kendall-test",
    "title": "In-class Exercise 2",
    "section": "4. Mann-Kendall Test",
    "text": "4. Mann-Kendall Test\nWith these Gi* measures, we can evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses Changsha county.\n\ncbg <- gi_stars %>%\n  ungroup() %>%\n  filter(County == \"Changsha\") |>\n  select(County, Year, gi_star)\n\nNext, we will plot the result by using ggplot2 functions.\n\np <- ggplot(data = cbg,\n            aes(x = Year,\n                y = gi_star)) +\n  geom_line() + \n  theme_light()\n \nggplotly(p)\n\n\n\n\n\nNote: we could need to install kendall package. (Install packages via tools > cran as I am not able to run on pacman due to version issues)\n\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 0.485 0.00742    66  136.  589."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#perform-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#perform-emerging-hotspot-analysis",
    "title": "In-class Exercise 2",
    "section": "5. Perform Emerging Hotspot Analysis",
    "text": "5. Perform Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object c (i.e GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation is performed.\n\nehsa <- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim =99\n  )\n\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\nWe could observe that the sporadic coldspot has the higher number of county."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#visualizing-ehsa",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#visualizing-ehsa",
    "title": "In-class Exercise 2",
    "section": "Visualizing EHSA",
    "text": "Visualizing EHSA\nWe will visualize the geographic distribution EHSA classes. Before we do so, we will need to join both hunna and ehsa together.\n\nhunan_ehsa <- hunan %>%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\nehsa_sig <- hunan_ehsa %>%\n  filter(p_value <0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha =0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)"
  }
]