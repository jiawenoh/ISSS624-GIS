[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Exercise 3: Processing and Visualizing Flow Data",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if the packages below are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)\n\n\n\n\nWe will be using three data sets for this exercise. Data were retrieved for the following:\n\nPassenger Volume by Origin Destination Bus Stops data set for the month of October- Aspatial data\nBus Stop. - Geospatial data that provides the location of bus stop\nMPSZ-2019 - Geospatial data that provides the sub-zone boundary of URA Master Plan 2019.\n\nIn this exercise, we are interested to build an OD matrix with the above data sets.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nodbus <- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          <chr> \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            <chr> \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       <dbl> 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             <chr> \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      <chr> \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE <chr> \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         <dbl> 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\n\n\nAs identified, we will be using two geospatial data.\n\n\nThe code chunk below uses st_read() of sf package to import the busstop into R. The imported shapefile will be simple features object of sf.\n\nbusstop <- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %>%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\nThen, we will use the same approach to import MPSZ-2019 into R.\n\nmpsz <- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %>%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-extraction",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-extraction",
    "title": "Exercise 3: Processing and Visualizing Flow Data",
    "section": "2.1 Data Extraction",
    "text": "2.1 Data Extraction\nWe are interested in the commuting flows on Weekday between 6 to 9 o’clock. As such, we will run the following code :\n\n\nShow the code\nodbus6_9 <- odbus %>%\n  filter(DAY_TYPE == \"WEEKDAY\",\n         between(TIME_PER_HOUR, 6, 9)) %>%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n\n\n\n\n\n\nTip\n\n\n\nInstead of doing pipe on two filters, we could add in additional conditions in `filter()\n\n\nFor future use, we could save the output in rds format and re-import into the R environment.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 <- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "Exercise 3: Processing and Visualizing Flow Data",
    "section": "2.2 Geospatial Data Wrangling",
    "text": "2.2 Geospatial Data Wrangling\n\n2.2.1 Combine busstop and mpsz\nNext, we will populate the planning subzone code of mpsz sf data frame into busstop sf data frame through st_intersection() for point and polygon overlay. Note: the output will be a point sf object.\n\n\nShow the code\nbusstop_mpsz <- st_intersection(busstop, mpsz) %>%\n  select(BUS_STOP_N, SUBZONE_C) %>%\n  st_drop_geometry()\n\n\nSimilarly, we can save the data:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\n\n\n2.2.2 Append busstop_mpsz onto odbus6_9\nWe will be performing a left_join() to append the subzone code onto odbus6_9 data frame. To ensure that there is no duplicate, we can use unique() to retain the distinct records.\n\n\nShow the code\nod_data <- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %>%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE) %>%\n  unique() %>%\n  ungroup()\n\n\n\n\n2.2.3 Update od_data frame with MPSZ\nNext, we will update od_data data frame with the planning subzone codes.\n\n\nShow the code\nod_data <- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) %>%\n  unique() %>%\n  ungroup()\n\n\nThen, we will remove NA and sum the trips.\n\n\nShow the code\nod_data <- od_data %>%\n  rename(DESTIN_SZ = SUBZONE_C) %>%\n  drop_na() %>%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %>%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n#save output\nwrite_rds(od_data, \"data/rds/od_data.rds\")\nod_data <- read_rds(\"data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/data/geospatial/MPSZ-2019.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, tidyverse , and knitr packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-queen-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-queen-contiguity-based-neighbors",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.1 Computing (QUEEN) contiguity based neighbors",
    "text": "3.1 Computing (QUEEN) contiguity based neighbors\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\n1 most connected region with 11 neighbors, and\n2 least connected regions with only 1 neighbor.\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. E.g., to see the neighbors of the first polygon in the object, we could use the following code:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nFrom the output, we observed that polygon 1 have 5 neighbors. The respective polygons ID are stored in the hunan Spatial Polygons Data Frame Class.\nTo retrieve the country name of Polygon ID = 1, we can use the following code:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output shows that Polygon ID = 1 is Anxiang country. To know more about the five neighboring polygons that we have identified with, the below code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nSimilarly, we are able to retrieve the GDPPC of these five countries by using the code chunk below:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nAdditionally, we can display the complete weight matrix by using str() . For the purpose of this exercise, we will add [0:10] to display the first 10 list instead of the full 88.\n\nstr(wm_q[0:10])\n\nList of 10\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-rook-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#creating-rook-contiguity-based-neighbors",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.2 Creating (ROOK) contiguity based neighbors",
    "text": "3.2 Creating (ROOK) contiguity based neighbors\nThe code chunk below will be used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\nSimilar to section 3.1 in terms of area units and least connected regions.\nDiffers in the most connected area as Rook shows 10 neighbors whereas Queen shows 11 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#visualising-contiguity-weights",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.3 Visualising contiguity weights",
    "text": "3.3 Visualising contiguity weights\nWe will be using sf package to get the latitude and longitude of the polygon centroids which allow us to take a point and display a line to each neighboring point. To do so, we would require the coordinates in a separate data frame, and apply a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length.\nOur input vector will be geometry column of us.bound while our function will be st_centroid. Additionally, we will be using map_dbl variation of map from the purrr package.\nTo get our longitude value, we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1 which allows us to get the first value in each centroid and the longitude.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nSimilarly, we use the same approach to get latitude. However, we will replace 1 with 2.\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWith longitude and latitude, we can combine them through cbind() to put longitude and latitude into the same object and use head() to check the first few observations.\n\ncoords <- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-contiguity-based-neighbors-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-contiguity-based-neighbors-map",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "3.4 Plotting Contiguity based neighbors map",
    "text": "3.4 Plotting Contiguity based neighbors map\nWe will be plotting the contiguity based neighbors map for Queen, and Rock. Ideally, we are able to plot individually, or combined them together.\n\nQueenRookQueen and Rook\n\n\n\n\nShow the code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\nShow the code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\") \n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-leg-with-row-standarized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-leg-with-row-standarized-weights",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.1 Spatial leg with row-standarized weights",
    "text": "7.1 Spatial leg with row-standarized weights\n\nProcessOutput\n\n\nStep 1: Compute average neighbor GDPP value for each polygon. Often, these values are referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nStep 2: Append spatially lag GDPPC values onto hunan sf data frame\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nStep 3: Verify data frame\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\n\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-lag-as-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-lag-as-sum-of-neighboring-values",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.2 Spatial lag as sum of neighboring values",
    "text": "7.2 Spatial lag as sum of neighboring values\n\nProcessOutput\n\n\nTo begin, we can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw() function to explicitly assign these weights.\nStep 1: apply lapply() function to assign a value of 1 for each neighbor\nStep 2: apply nb2listw() function to explicitly assign these weights.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nStep 3: use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nStep 4: examine the result\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nStep 5: Append the lag_sum GDPPC into hunan sf data frame\n\nhunan <- left_join(hunan, lag.res)\n\n\n\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-average",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.3 Spatial window average",
    "text": "7.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element.\n\nProcessOutput\n\n\nStep 1: add diagonal element to the neighbor list by using include.self() from spdep\n\nwm_qs <- include.self(wm_q)\n\nStep 2: Check neighbor list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nStep 3: Obtain weights with nb2listw()\n\nwm_qs <- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nStep 4: create lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gpdpc <- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nStep 5: convert lag variable listw object into a dataframe by using as.data.frame()\n\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nStep 6: append lag_window_avg GDPPC values onto hunan sf data frame using left_join()\n\nhunan <- left_join(hunan, lag_wm_qs.res)\n\nStep 7: compare values of lag GDPPC and Spatial window average by using kable() of Knitr package\n\nhunan %>%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\nPlot lap_gdppc and w_ave_gdppc maps by using qtm() of tmap package\n\n\nShow the code\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-window-sum",
    "title": "Exercise 2A: Spatial Weights and Applications",
    "section": "7.4 Spatial window sum",
    "text": "7.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row- standardized weights.\n\nProcessOutput\n\n\nStep 1: add diagonal element to the neighbor list by using include.self() from spdep\n\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nStep 2: Assign binary weights to the neighbor structure that includes the diagonal element\n\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nStep 3: Explicitly assign weight values by using nb2listw() and glist()\n\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nStep 4: compute lag variable with lag.listw()\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nStep 6: convert lag variable listw object into a dataframe by using as.data.frame()\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nStep 7: append w_sum GDPPC values into hunan sf data frame by using left_join()\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nStep 8: compare values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\nPlot lap_sum GDPPC and w_sum_gdppc maps by using qtm() of tmap package\n\n\nShow the code\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in.\n\n\n\nAfter joining, we will do a quick visualization. We will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012.\n\n\nShow the code\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-append-local-morans-i-with-spdf",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-append-local-morans-i-with-spdf",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 1: Append Local Moran’s I with SPDF",
    "text": "Step 1: Append Local Moran’s I with SPDF\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-map-local-morans-i-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-map-local-morans-i-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 2: Map local Moran’s I values",
    "text": "Step 2: Map local Moran’s I values\nUsing choropleth mapping function of tmap package, we can plot the local Moran’s I values:\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-map-local-morans-i-p-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-map-local-morans-i-p-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 3: Map local Moran’s I p-values",
    "text": "Step 3: Map local Moran’s I p-values\nAs seen above, Ii contains both positive and negative values. Thus, it is useful for us to consider the p-values for each values.\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-optional-map-both-local-morans-i-values-and-p-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-optional-map-both-local-morans-i-values-and-p-values",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 4 (Optional) : Map both local Moran’s I values and p-values",
    "text": "Step 4 (Optional) : Map both local Moran’s I values and p-values\nFor effective interpretation, we can plot both I-values and corresponding p-values next to one another.\n\n\nShow the code\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-vectorize",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-1-vectorize",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 1: Vectorize",
    "text": "Step 1: Vectorize\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-derive-spatially-lagged-variable-of-interest-and-centers-it-around-its-mean",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-2-derive-spatially-lagged-variable-of-interest-and-centers-it-around-its-mean",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 2: Derive Spatially lagged variable of interest and centers it around its mean",
    "text": "Step 2: Derive Spatially lagged variable of interest and centers it around its mean\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-center-the-local-morans-around-the-mean",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-3-center-the-local-morans-around-the-mean",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 3: Center the local Moran’s around the mean",
    "text": "Step 3: Center the local Moran’s around the mean\n\nLM_I <- localMI[,1] - mean(localMI[,1])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-set-statistical-significance-level-for-the-local-moran",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-4-set-statistical-significance-level-for-the-local-moran",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 4: Set statistical significance level for the local Moran",
    "text": "Step 4: Set statistical significance level for the local Moran\n\nsignif <- 0.05"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-5-define-the-quadrants",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-5-define-the-quadrants",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 5: Define the quadrants",
    "text": "Step 5: Define the quadrants\n1 = low-low 2 = low - high 3 = high - low 4 = high - high\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-6-place-non-significant-moran-in-category-0",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#step-6-place-non-significant-moran-in-category-0",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Step 6: Place non-significant Moran in Category 0",
    "text": "Step 6: Place non-significant Moran in Category 0\n\nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#final-output",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#final-output",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Final Output:",
    "text": "Final Output:\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#deriving-the-centriod",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#deriving-the-centriod",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.1 Deriving the centriod",
    "text": "1.1 Deriving the centriod\nBefore making our connectivity graph, we will need to associate each polygon. We will use a mapping function to get the longitude, latitude and thereafter, combine them together.\n\n#get longitude\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n#get latitude\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n#combine\ncoords <- cbind(longitude, latitude)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#determine-the-cut-off-distance",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.2 Determine the cut-off distance",
    "text": "1.2 Determine the cut-off distance\nWe need to determine the upper list for distance band by :\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n\nShow the code\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nAs seen above, the max distance is 61.79km. We can infer that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-fixed-distance-weight-matrix",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.3 Compute fixed distance weight matrix",
    "text": "1.3 Compute fixed distance weight matrix\nWe will compute the distance weight matrix by using dnearneigh():\n\n\nShow the code\n#compute distance weight matrix \nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#compute-adaptive-distance-weight-matrix",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "1.4 Compute adaptive distance weight matrix",
    "text": "1.4 Compute adaptive distance weight matrix\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#gi-statistics-using-fixed-distance",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "Gi Statistics using fixed distance",
    "text": "Gi Statistics using fixed distance\nNotably, the output of localG() is a vector of G or Gstar values, with attributes gstari set to TRUE or FALSE. The Gi stats represents the z-score where greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\n\n\nShow the code\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed \n\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below by converting the output vector (gi.fixed) into r matrix object by using as.matrix(). Then, cbind() to join hunan data and gi.fixed matrix to produce a new Spatial Polygon Data Frame called hunan.gi.\nLastly, it will be rename to gstat_fixed by using rename().\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#fixed-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#fixed-distance-weights",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "fixed distance weights",
    "text": "fixed distance weights\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#adaptive-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02c.html#adaptive-distance-weights",
    "title": "Exercise 2C: Local Measures of Spatial Autocorrelation",
    "section": "adaptive distance weights",
    "text": "adaptive distance weights\n\n\nShow the code\n# compute the Gi value \nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf, spdep, tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 19th Nov 2023. They are :\n\nHunan country boundary layer*. (data is in ESRI shapefile format) - Geospatial data\nHunan_2012.csv*. (data is in csv file) - Attribute table\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will update the attribute table of hunan’s Spatial Polygons Data Frame with the attribute fields of hunan2012 dataframe. We will performed a left_join() with the aid of dplyr package.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4,7,15)\n\nWe will be joining both tables by County. By doing the left_join, we will combined the 8 variables from hunan, with 29 variables from hunan2012 and uses select() to filter for the variables that we are interested in.\n\n\n\nAfter joining, we will do a quick visualization. We will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012.\n\n\nShow the code\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#computing-contiguity-spatial-weights",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.1 Computing Contiguity Spatial Weights",
    "text": "2.1 Computing Contiguity Spatial Weights\nTo begin with, we are require to construct a spatial weights of the study area. The spatial weights is used to define the neighborhood relationships between the geographical units (i.e. county) in the study area. We will be using poly2nb() of spdep package to compute QUEEN contiguity weight matrices for the study area.\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nObservations:\n\nSummary report highlights 88 area units in Hunan.\n1 most connected region with 11 neighbors, and\n2 least connected regions with only 1 neighbor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#row-standardised-weights-matrix",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.2 Row-standardised weights matrix",
    "text": "2.2 Row-standardised weights matrix\nNext, we would need to assign weights to each neighboring polygon. Weights are assigned based on the fraction of 1/#no.of neighbors to each neighboring country then summing the weighted income values.\nFor the example below, we will used style = ‘W’ option (note: there are robust options available). By adding ’Zero.police = TRUE’, we are allowing list of non-neighbors.\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote about nb2listw()\n\n\n\n\n\nnb2listw() has two major arguments, namely style and zero.policy.\nThere are 6 Styles, namely:\n\n“W” : row standardize (sum over all links to n)\n“B” : basic binary coding\n“C” : globally standardised (sum over all links to n)\n“U” : is equal to C divided by the number of neighbors (sum over all links to unity)\n“minmax” : the min, and max\n“S” : variance-stabilizing coding scheme\n\nThe default setting for zero.policy:\n\n‘NULL’ : (default), uses global option value\n‘TRUE’ : permit the weights list to be formed with zero-length weights vectors\n‘FALSE’ : stop with error for any empty neighbors sets\n\nRefer here for more information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#morans-i-statistics-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#morans-i-statistics-test",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.3 Moran’s I Statistics test",
    "text": "2.3 Moran’s I Statistics test\nThere are two tests that we could perform. In this section, we will cover the Moran’s I test. We will be using moran.test() of spdep to perform the statistical test.\n\nMoran’s I TestMonte Carlo Moran’s IVisualisation\n\n\nWe will perform Moran’s I statistical testing using moran.test() of spdep:\n\n\nShow the code\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nAs observed, we can reject the null hypothesis (Ho) as the p-value is smaller than the alpha value.\n\n\nWe will perform permutation test for Moran’s statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed:\n\n\nShow the code\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nAs observed, we can reject the null hypothesis (Ho) as the p-value is smaller than the alpha value.\n\n\nWe will be examining the simulated Moran’s I test statistic by plotting the distribution of the statistical values through a histogram:\n\n\nShow the code\n#print mean\ncat('The mean is:', mean(bperm$res[1:999]),'\\n')\n\n\nThe mean is: -0.01504572 \n\n\nShow the code\n#print variance\ncat('The variance is:', var(bperm$res[1:999]), '\\n')\n\n\nThe variance is: 0.004371574 \n\n\nShow the code\n#print summary\ncat('Summary Report\\n')\n\n\nSummary Report\n\n\nShow the code\nsummary(bperm$res[1:999])\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\nShow the code\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#gearys-statistics-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#gearys-statistics-test",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "2.4 Geary’s Statistics Test",
    "text": "2.4 Geary’s Statistics Test\nIn this section, we will cover the Geary’s C test. We will be using geary.test() of spdep to perform the statistical test.\n\nGeary’s C TestMonte Carlo Geary’s CVisualisation\n\n\nWe will perform Geary’s C statistical testing using geary.test() of spdep:\n\n\nShow the code\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\nWe will perform permutation test for Geary’s statistic by using geary.mc() of spdep. A total of 1000 simulation will be performed:\n\n\nShow the code\nset.seed(1234)\ngperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\ngperm\n\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nWe will be examining the simulated Geary’s C test statistic by plotting the distribution of the statistical values through a histogram:\n\n\nShow the code\n#print mean\ncat('The mean is:', mean(gperm$res[1:999]),'\\n')\n\n\nThe mean is: 1.004402 \n\n\nShow the code\n#print variance\ncat('The variance is:', var(gperm$res[1:999]), '\\n')\n\n\nThe variance is: 0.007436493 \n\n\nShow the code\n#print summary\ncat('Summary Report\\n')\n\n\nSummary Report\n\n\nShow the code\nsummary(gperm$res[1:999])\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\n\nShow the code\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-morans-i-correlogram",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "3.1 Compute Moran’s I correlogram",
    "text": "3.1 Compute Moran’s I correlogram\nThe global spatial autocorrelation used in Moran’s I. For the graph, we will use plot() of base graph.\n\n\nShow the code\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nTo get a better interpretation of the output, we can examine the full analysis by printing the results.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-gearys-c-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#compute-gearys-c-correlogram",
    "title": "Exercise 2B: Global Measures of Spatial Autocorrelation",
    "section": "3.2 Compute Geary’s C correlogram",
    "text": "3.2 Compute Geary’s C correlogram\nThe global spatial autocorrelation used in Geary’s C. For the graph, we will use plot() of base graph.\n\n\nShow the code\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nTo get a better analysis,\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\nIn this section, the following data will be imported into R through st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL , a polygon feature layer in ESRI shapefile format\nCyclingPath , a line feature layer in ESRI shapefile format, and\nPreSchool , a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() of sf package to import MP14_SUBZONE_WEB_PL:\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nIt can be observed that there are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems.\n\n\n\nThe code chunk below uses st_read() of sf package to import CyclingPath shapefile:\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nIt can be observed that there are a total of 2,558 features and 2 fields in cyclingpath linestring feature data frame. It is in svy21 projected coordinates systems.\n\n\n\nThe code chunk below will be used to import the kml (pre-schools-location-kml) into R:\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nIt can be observed that there are a total of 2,290 features and 2 fields in preschool point feature data frame. It is a wgs84 coordinates systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.1 Working with st_geometry()",
    "text": "2.1 Working with st_geometry()\nBy using mpsz$geom or mpsz[[1]], we can retrieve the geometry list-column which only display basic information of the feature class, such as type of geometry, geographic extent of the features and the coordinate system of the data.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.2 Working with glimpse ()",
    "text": "2.2 Working with glimpse ()\nBy using glimpse() of dplyr, we are able to learn more about the associated attribution information in the data frame. It reveals the data type of each fields (e.g., FMEL-UPD_D is in data data type, and X_ADDR is a double-precision values)\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "2.3 Working with head()",
    "text": "2.3 Working with head()\nInstead of printing the complete information, head() allow users to select the numbers of record to display (i.e., the n argument)\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "4.1 Assigning EPSG code to a simple feature data frame",
    "text": "4.1 Assigning EPSG code to a simple feature data frame\nIn the code chunk below, it illustrates the coordinate system of mpsz simple feature data frame by using st_crs() of sf package:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAs seen from the result, the EPSG code is inaccurate. Instead of showing 3414 (svg21), it displays 9001 (last row). This is a common issue that could happen in the process of importing geospatial data into R. The coordinate system of the source data could be missing or wrongly assigned.\nIn order to rectify the EPSG code, we will use the st_set_crs() of sf package:\n\nmpsz3414 <- st_transform(mpsz, 3414)\n\nTo validate, we will used the code chunk below:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-project-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-project-of-preschool-from-wgs84-to-svy21",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "4.2 Transforming the project of preschool from wgs84 to svy21",
    "text": "4.2 Transforming the project of preschool from wgs84 to svy21\nNotably, it is common for us to transform original data from geographic coordinate system to projected coordinate system as the geographic coordinate system is not appropriate if the analysis requires distance and/or area measurements.\nWe performed the project transformation by using the code chunk below:\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)\n\nTo display the first 5 geometries and content of the preschool3414 data frame, we will use head():\n\nhead(preschool3414, n=5)\n\nSimple feature collection with 5 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 24821.92 ymin: 31299.16 xmax: 28844.56 ymax: 46303.16\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n   Name\n1 kml_1\n2 kml_2\n3 kml_3\n4 kml_4\n5 kml_5\n                                                                                                                                                                                                                                                                                                                                                                                                Description\n1           <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S COVE PRESCHOOL PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9390</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>498CC9FE48CC94D4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n2                    <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S COVE PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT8675</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>22877550804213FD</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n3       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDREN'S VINEYARD PRESCHOOL PTE. LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9308</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>B2FE90E44AD494E3</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n4 <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILDTIME CARE & DEVELOPMENT CENTRE PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9122</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>1384CDC0D14B76A1</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n5                               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CHILTERN HOUSE</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT2070</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>FB24EAA6E73B2723</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20211201093631</td> </tr></table></center>\n                       geometry\n1 POINT Z (25089.46 31299.16 0)\n2 POINT Z (27189.07 32792.54 0)\n3 POINT Z (28844.56 36773.76 0)\n4 POINT Z (24821.92 46303.16 0)\n5 POINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "5.1 Importing the aspatial data",
    "text": "5.1 Importing the aspatial data\nFor the purpose of the exercise, we will be using the Singapore listing (listings.csv) as retrieved from AirBnb.\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nTo ensure data accuracy, we will check if the data file have been imported correctly. The code chunk below uses list() of Base R instead of glimpse().\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    <dbl> <chr>       <dbl> <chr>     <chr>               <chr>            <dbl>\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude <dbl>, room_type <chr>, price <dbl>,\n#   minimum_nights <dbl>, number_of_reviews <dbl>, last_review <date>,\n#   reviews_per_month <dbl>, calculated_host_listings_count <dbl>,\n#   availability_365 <dbl>, number_of_reviews_ltm <dbl>, license <chr>\n\n\nObservations:\n\nTibble data frame consists of 3,483 rows and 18 columns\nUseful fields for our analysis : latitude and longitude (note: decimal degree format)\n\nAssumption:\n\nData is in wgs84 geographic coordinate system"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "5.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "5.2 Creating a simple feature data frame from an aspatial data frame\nIn the code chunk below, we will be using st_as_sf() of sf package to convert listing data frame into a simple feature data frame:\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\n\n\n\nNote\n\n\n\ncoords : to provide x-coordinates, y-coordinates\ncrs : to provide the coordinates system in EPSG format.\nEPSG: 4326 is wgs84 Geographic Coordinate System\nEPSG : 3414 is Singapore SVY21 Projected Coordinate System.\nFor more information, do refer to epsg.io\n\n\nTo examine the content of our newly created simple feature data frame:\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             <dbl> 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           <chr> \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        <dbl> 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      <chr> \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            <chr> \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  <chr> \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 <dbl> 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              <dbl> 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    <date> 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              <dbl> 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count <dbl> 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               <dbl> 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        <chr> NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       <POINT [m]> POINT (41972.5 36390.05), POINT (…\n\n\nObservation:\n\nInstead of longitude and latitude, a new column called geometry has been added into the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "6.1 Buffering",
    "text": "6.1 Buffering\nThe scenario: The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path.\nThe task: To determine the extend of the land need to be acquired and their total area.\nThe solution:\nIn the code chunk below, we will be using st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThen, we calculate the area of the buffers:\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nLastly, we use sum() of Base R to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "6.2 Point-in-polygon count",
    "text": "6.2 Point-in-polygon count\nThe scenario: A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\n\n\n\n\n\n\n\nWarning\n\n\n\nBe careful and do not be confuse with st_intersection() !\n\n\nWe can check the summary statistics of the newly derieved Presch Count Field by using summary() as shown in the code chunk below:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below:\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe solution:\nStep 1: Use st_area() of sf package to derive the area of each planning subzone\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\nStep 2: Apply mutate() of dplyr package to compute the density\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-histogram",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "7.1 Plotting Histogram",
    "text": "7.1 Plotting Histogram\nTo observe the distribution of PreSch Density, a histogram is insightful. We can used hist() of R graphics or ggplot2 to plot.\n\n7.1.1 Histogram using hist()\n\n\nShow the code\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nDespite the easy syntax, the output is far from ideal as it limits further customization.\n\n\n7.1.2 Histogram using ggplot2()\n\n\nShow the code\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-scatterplot",
    "title": "Exercise 1A: Geospatial Data Wrangling",
    "section": "7.2 Plotting Scatterplot",
    "text": "7.2 Plotting Scatterplot\nTo observe the relationship between Pre-school Density and Pre-school count, a scatterplot could be ideal.\n\n\nShow the code\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if sf , tmap, and tidyverse packages are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNote: readr, tidyr, and dplyr are part of tidyverse package\n\n\n\nIn this section, the following data will be imported into R through st_read() of sf package to create the choropleth map:\n\nMP14_SUBZONE_WEB_PL, in ESRI shapefile format, retrieved from data.gov.sg\nrespopagsex2010to2020.csv - Singapore Residents by Planning Area/Subzone, Age Group, Sex, and Type of Dwelling, June 2011-2020, retrieved from Department of Statistics, Singapore.\n\n\n\nWe will be using st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n#to examine the content\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nWe will be using read_csv() function of readr package to import respopagsex2010to2020.csv into R and save the file as a dataframe called popdata.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore we prepared for a thematic map, we would need to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by(), and select() of dplyr package\n\n\n\nShow the code\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nAfter the transformation, we will need to convert the values in PA and SZ fields to uppercase to standardize the fields. PA and SZ fields are made up of upper-and lowercase while SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nThereafter, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone (e.g. SUBZONE_N and SZ as the common identifier)\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nBy using the code chunk below, we can write a .rds file to save data into R data format.\n\nwrite_rds(mpsz_pop2020, \"data/aspatial/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-choropleth-map-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-choropleth-map-using-qtm",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.1 Plot Choropleth map using qtm()",
    "text": "2.1 Plot Choropleth map using qtm()\nqtm() provides the quickest way to draw a choropleth map. It is concise and provides a good default visualization as seen in the code chunk below.\n\n\nShow the code\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\nLearning points:\n\nTmap_mode()\n\n“Plot” is used to produce static map.\nView” is used to produce interactive mode\n\nfill argument is used to map the attribute (i.e., Dependency)\nHard to control the aesthetics of individual layers"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#plot-using-tmaps-elements",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.2 Plot using tmap’s elements",
    "text": "2.2 Plot using tmap’s elements\nAlthough we are able to plot quickly and easily through qtm(), we are not able to draw a high quality cartographic choropleth map. As seen in the code chunk below, tmap’s drawing elements are used to add area patterns or graduated colors.\n\n2.2.1 Drawing a base map\nStep 1: To begin building the block of tmap, we will used tm_shape() to define the input data and tm_polygons() to draw the planning subzone polygons.\n\n\nShow the code\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n2.2.2 Use tm_polygons()\nStep 2: To show the geographical distribution of a selected variable by planning subzone, we will assign the target variable such as Dependency to tm_polygons(). Note: default color is Yl0rRd of ColorBrewer. By default, missing value will be shaded in grey.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n2.2.3 Use tm_fill() and tm_border()\nStep 2: Instead of using tm_polygons() in section 2.2.2, tm_fill() could be used as well. Notably, tm_polygons() is a wraper of tm_fill() and tm_borders(). tm_fill() shades the polygons by default colour scheme whereas tm_borders() add the borders of the shapefile.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\nTo add boundary to the planning subzone, tm_borders() will be used.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nLearning Points:\n\n‘alpha’ is used to define transparency (range from 0 to 1) with 1 as default (non-transparent)\n‘col’ refers to border color\n‘lwd’ refers to border line width. Default as 1.\n‘lty’ refers to border line type. Default as solid.\n\n\n\n2.2.4 Final Choropleth Map\nStep 3: After adding the base map, planning subzone, colors, borders, the code chunk below reveals the finalized output with functional choropleth map.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#data-classification-methods-of-tmap",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.3 Data Classification Methods of tmap",
    "text": "2.3 Data Classification Methods of tmap\ntmap provides a total of 10 data classifications methods, namely- fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. To define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.3.1 Built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nBy changing the style, the distribution will look different. The code chunk below used equal data classification method.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nIn comparison, quantile method is evenly distributed. In addition, we observed that by increasing the number of classes, the graduated colors become more distinct.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.3.2 Custome Break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Thus, our breaks vector is c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\nWe will be able to plot the choropleth map by using the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#color-scheme",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.4 Color Scheme",
    "text": "2.4 Color Scheme\ntmap supports color ramps either defined by the user or a set of predefined color ramps from the RColorBrewer package.\n\n2.4.1 RColorBrewer Package\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n- : reverse the color shading."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#map-layouts",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.5 Map Layouts",
    "text": "2.5 Map Layouts\nAs covered in previous section, the palette and break-points could affect how the map looks. Moreover, the combination of all map elements such as objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios create a cohesive map.\n\n2.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.5.2 Map Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style(). We will be using the classic style for the example below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n2.5.3 Cartographic Furniture\ntmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines. tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map in the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n2.5.3.1. Reset Default Style\nIf needed, the code chunk below helps to reset the default style.\nOther available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#facet-maps",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.6 Facet Maps",
    "text": "2.6 Facet Maps\nMaps could be arrange side-by-side into multiple small maps, stacked vertically or horizontally. It enable the visualization of how spatial relationships changes with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.6.1 Assign multiple values\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill() :\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\nLikewise, we could assign multiple values to at least one of the aesthetic arguments and highlight in different color.\n\n\nShow the code\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n2.6.2 Group-by variable in tm_facets()\nMultiple small choropleth maps are created by using tm_facets() as seen in the code below:\n\n\nShow the code\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.6.3 Multiple stand-alone maps with tmap_arrange()\nMultiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange() as seen in the code below:\n\n\nShow the code\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Exercise 1B: Choropleth Mapping",
    "section": "2.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "2.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating multiple choropleth map, we can use selection function to map spatial objections meeting the selection criterion.\n\n\nShow the code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624 Applied Geospatial Analytics",
    "section": "",
    "text": "Welcome to my learning journey in ISSS624 Applied Geospatial Analytics . In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "The digitization of city-wide urban infrastructures such as buses,mass rapid transit enable collection of massive data sets on patterns such as human movement and behaviors within the city. In real-world practices, the use of these data are confined to simple tracking and mapping with GIS applications due to the lack of functions in conventional GIS.\n\n\nThis exercise aims to reveals the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore using appropriate geovisualisation techniques and analysis.\nThe original data set was downloaded on 18th November 2023 from LTA DataMall under Section 2.6 - Passenger Volume by Origin Destination Bus Stops. It records the number of trips by weekdays and weekends from origin to destination bus stops.\nA total of three files were downloaded :\n\norigin_destination_bus_202308.csv\norigin_destination_bus_202309.csv\norigin_destination_bus_202310.csv\n\nThe focus of the study will be on the August data."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "title": "Take Home Exercise 1",
    "section": "2.1 Install R packages",
    "text": "2.1 Install R packages\nThe code chunk below uses pacman:: p_load() to load and install the following libraries:\n\nmapview : Used to create interactive visualization of spatial data\nknitr: Used for dynamic report generation\npatchwork : Used to combine multiple ggplot graphs into the same graphic\nsf : Used for geospatial data handling\nspdep : Used to create spatial weights matrix objects\nsfdep : Used to integrate with 'sf' objects and the 'tidyverse'\ntidyverse: A collection of R packages use in everyday data analyses. It is able to support data science, data wrangling, and analysis\ntmap : Used for thematic mapping\n\n\npacman::p_load(mapview, knitr, patchwork, sf, spdep, sfdep, tidyverse, tmap)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#import-and-load-dataset",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#import-and-load-dataset",
    "title": "Take Home Exercise 1",
    "section": "2.2 Import and Load Dataset",
    "text": "2.2 Import and Load Dataset\nThree geospatial data will be used for this study, they are:\n\norigin_destination_bus_202308.csv : A csv file containing information about all the bus stops currently being serviced by bus, which includes bus stop identifier, and location coordinates.\nMPSZ-2019: A ESRI shapefile format, based on URA Master Plan 2019.\nhexagon : A hexagon layer of 250m to replace the relative coarse and irregular Master Plan 2019 Planning Sub-Zone GIS data of URA\n\n\n2.2.1 Importing Aspatial data\nFirst, we will import the Passenger Volume by Origin Destination Bus Stops data set for August by using readr::read_csv() and store it in variable odbus. Also, we will be using glimpse() report to reveal the data type of each field.\nPoint to note: ORIGIN_PT_CODE and DESTINATION_PT_CODE are in <chr> format.\n\n\nShow the code\nodbus <- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\nglimpse(odbus)\n\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          <chr> \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            <chr> \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       <dbl> 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             <chr> \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      <chr> \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE <chr> \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         <dbl> 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\n\n\n2.2.2 Importing Geospatial data\nThereafter, we will import the Passenger Volume by Origin Destination Bus Stops data set for August.\n\n2.2.2.1 Import Bus Stop data\nWe will be using sf::st_read() to import and sf::st_transform() to ensure that the projected coordinate system is in the right format before storing in variable busstop. Also, we will be using glimpse() report to reveal the data type of each field.\n\nbusstop <- st_read(dsn = \"data/geospatial\",layer = \"BusStop\") %>%\n    st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/Take-Home_Ex/Take-Home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nThe message above shows that there are a total of 5161 features and 3 fields in busstop point feature data frame and it is in SVY21 projected coordinates system.\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N <chr> \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N <chr> \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   <chr> \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   <POINT [m]> POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\n\n\n\n\n\nNote about coordinates system\n\n\n\n\n\ncrs : to provide the coordinates system in EPSG format.\nEPSG: 4326 is wgs84 Geographic Coordinate System\nEPSG : 3414 is Singapore SVY21 Projected Coordinate System.\nFor more information, do refer to epsg.io"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\nLooking at the section 2.2.1, we noticed a few problem:\n\nORIGIN_PT_CODE : is in <chr> format.\nDESTINATION_PT_CODE : is in <chr> format.\n\nWe will be using dplyr::mutate() to convert the <chr> data type to <fct> and store it in a new variable odbus_new.\n\n\nShow the code\nodbus_new <- odbus %>%\n mutate(ORIGIN_PT_CODE = as.factor(ORIGIN_PT_CODE),\n        DESTINATION_PT_CODE = as.factor(DESTINATION_PT_CODE))\n\nglimpse(odbus_new)\n\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          <chr> \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            <chr> \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       <dbl> 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             <chr> \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      <fct> 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE <fct> 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         <dbl> 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nAdditionally, we confirmed that there are no missing values in the odbus_new data set.\n\nany(is.na(odbus_new))\n\n[1] FALSE\n\n\n\n2.3.1 Data Extraction\nIn this section, we will extract commuting flows based on the table below.\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nThe code is extracted in the following manner:\n\nfilter() is used to extract subset of data\nbetween() is used to express a range condition\ngroup_by() and summarise() are used to sum the total trips\narrange(desc()) to sort in descending order\nungroup() is used to end a definition, often use with group_by()\n\n\n\nShow the code\n#weekday morning peak \nwkd6_9 <- odbus_new %>%\n  filter(DAY_TYPE == \"WEEKDAY\",\n         between(TIME_PER_HOUR, 6, 9)) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  arrange(desc(TRIPS)) %>%\n  ungroup()\n\n#weekday afternoon peak \nwkd17_20 <- odbus_new %>%\n  filter(DAY_TYPE == \"WEEKDAY\",\n         between(TIME_PER_HOUR, 17, 20)) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  arrange(desc(TRIPS)) %>%\n  ungroup()\n\n#weekend/holiday morning peak \nwknd11_14 <- odbus_new %>%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\",\n         between(TIME_PER_HOUR, 11, 14)) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  arrange(desc(TRIPS)) %>%\n  ungroup()\n\n#weekend/holiday afternoon peak \nwknd16_19 <- odbus_new %>%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\",\n         between(TIME_PER_HOUR, 16, 19)) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  arrange(desc(TRIPS)) %>%\n  ungroup()\n\n\n\nWeekday (0600-0900)Weekday (1700-2000)Weekends/Holidays (1100-1400)Weekends/Holidays (1600-1900)\n\n\n\nkable(head(wkd6_9))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n22009\n365871\n\n\n46009\n294601\n\n\n75009\n170187\n\n\n52009\n144079\n\n\n24009\n141698\n\n\n55509\n129362\n\n\n\n\n\n\n\n\nkable(head(wkd17_20))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n22009\n536630\n\n\n46009\n457783\n\n\n75009\n352578\n\n\n59009\n315889\n\n\n84009\n227886\n\n\n52009\n224010\n\n\n\n\n\n\n\n\nkable(head(wknd11_14))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n22009\n102210\n\n\n46009\n95185\n\n\n59009\n73678\n\n\n75009\n73479\n\n\n84009\n67932\n\n\n52009\n63651\n\n\n\n\n\n\n\n\nkable(head(wknd16_19))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n22009\n143443\n\n\n46009\n118771\n\n\n75009\n97207\n\n\n59009\n88385\n\n\n84009\n74928\n\n\n52009\n70262\n\n\n\n\n\n\n\n\nThereafter, we will save a copy of the output in rds format and reload it into the environment.\n\n\nShow the code\n#weekday morning peak \nwrite_rds(wkd6_9, \"data/rds/wkd6_9.rds\")\nwkd6_9 <- read_rds(\"data/rds/wkd6_9.rds\")\n\n#weekday afternoon peak \nwrite_rds(wkd17_20, \"data/rds/wkd17_20.rds\")\nwkd17_20 <- read_rds(\"data/rds/wkd17_20.rds\")\n\n#weekend/holiday morning peak \nwrite_rds(wknd11_14, \"data/rds/wknd11_14.rds\")\nwknd11_14 <- read_rds(\"data/rds/wknd11_14.rds\")\n\n#weekend/holiday afternoon peak \nwrite_rds(wknd16_19, \"data/rds/wknd16_19.rds\")\nwknd16_19 <- read_rds(\"data/rds/wknd16_19.rds\")\n\n\n\n\n2.3.2 Combining Data\nBefore we proceed, we will used mapview() as a default visualization.\n\n\nShow the code\nmapview_check = mapview(busstop, cex = 3, alpha = .5, popup = NULL)\n\nmapview_check\n\n\n\n\n\n\nAs observed, there are 5 bus stops that are not within Singapore Map that includes Passenger Volume by Origin Destination Bus Stop. Although we are able to filter and remove bus stops that are not within the Singapore Boundary, it might be interesting to observe the community flows from Singapore to Johor Bahru. As such we will not remove these data points.\n\n2.3.2.1 Combine commuting flow into busstop\nAfter populating the commuting flow, we will combine it into busstop sf data frame. To ensure that all bus stops are distinct, we will be using dplyr:: mutate() to replace N/A to 0 and add unique() function into our code to keep distinct flows.\n\n\nShow the code\n#weekday morning peak \norigin_SZ_wkd6_9 <- left_join(busstop, wkd6_9,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) %>%\n      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  unique() %>%\n  ungroup()\n\n#weekday afternoon peak \norigin_SZ_wkd17_20 <- left_join(busstop, wkd17_20,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) %>%\n      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  unique() %>%\n  ungroup()\n\n#weekend/holiday morning peak \norigin_SZ_wknd11_14 <- left_join(busstop, wknd11_14,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) %>%\n      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  unique() %>%\n  ungroup()\n\n#weekend/holiday afternoon peak \norigin_SZ_wknd16_19 <- left_join(busstop, wknd16_19,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) %>%\n      mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  unique() %>%\n  ungroup()\n\n\n\n\n2.3.2.2 Create Hexagon Layer\nHexagons are the densest way to pack circles in tessellation and reduce edge effects. With reference to Urban Data Palette, we will create honeycomb grid through the following steps:\n\nst_make_grid() : create a regular grid of spatial polygons. Revision have been done to the cell width and height to c(500,500).\nst_sf() : convert the honeycomb grid object to an sf object. Grid ID is created to count the number of bus stops and sum of trips in the grid.\nst_intersects() : determine whether two sets of spatial objects intersect.\nst_join() : join two spatial objects based on their spatial relationships by intersections.\n\n\n\nShow the code\n#weekday morning peak \nhoneycomb_grid_wkd6_9 = st_make_grid(origin_SZ_wkd6_9, c(500, 500), #cell revised\n                              what = \"polygons\", square = FALSE)\nhoneycomb_grid_sf_0609 = st_sf(honeycomb_grid_wkd6_9) %>%\n  mutate(grid_id = 1:length(lengths(honeycomb_grid_wkd6_9)))\nintersections0609 <- st_intersects(origin_SZ_wkd6_9, honeycomb_grid_sf_0609)\njoin_df0609 <- st_join(honeycomb_grid_sf_0609, origin_SZ_wkd6_9, by = intersections0609)\n\n#weekday afternoon peak \nhoneycomb_grid_wkd17_20 = st_make_grid(origin_SZ_wkd17_20, c(500, 500), \n                              what = \"polygons\", square = FALSE)\nhoneycomb_grid_sf_1720 = st_sf(honeycomb_grid_wkd17_20) %>%\n  mutate(grid_id = 1:length(lengths(honeycomb_grid_wkd17_20)))\nintersections1720 <- st_intersects(origin_SZ_wkd17_20, honeycomb_grid_sf_1720)\njoin_df1720 <- st_join(honeycomb_grid_sf_1720, origin_SZ_wkd17_20, by = intersections1720)\n\n#weekend/holiday morning peak \nhoneycomb_grid_wknd11_14 = st_make_grid(origin_SZ_wknd11_14, c(500, 500), \n                              what = \"polygons\", square = FALSE)\nhoneycomb_grid_sf_1114 = st_sf(honeycomb_grid_wknd11_14) %>%\n  mutate(grid_id = 1:length(lengths(honeycomb_grid_wknd11_14)))\nintersections1114 <- st_intersects(origin_SZ_wknd11_14, honeycomb_grid_sf_1114)\njoin_df1114 <- st_join(honeycomb_grid_sf_1114, origin_SZ_wknd11_14, by = intersections1114)\n\n#weekend/holiday afternoon peak \nhoneycomb_grid_wknd16_19 = st_make_grid(origin_SZ_wknd16_19, c(500, 500), \n                              what = \"polygons\", square = FALSE)\nhoneycomb_grid_sf_1619 = st_sf(honeycomb_grid_wknd16_19) %>%\n  mutate(grid_id = 1:length(lengths(honeycomb_grid_wknd16_19)))\nintersections1619 <- st_intersects(origin_SZ_wknd16_19, honeycomb_grid_sf_1619)\njoin_df1619 <- st_join(honeycomb_grid_sf_1619, origin_SZ_wknd16_19, by = intersections1619)\n\n\n\n\n2.3.2.3 Extract Data\nAfter creating the joined data frame, we are interested in knowing the number of bus stops that is in the grid_id and the total number of trips. As such, we performed the following steps:\n\nmutate() : Used to replace TRIPS with N/A to 0.\nfilter() : Used to remove data with 0 trip\ngroup_by(): Used to group data based on grid_id.\nsummarize() :\n\nn() : Used to count number of bus stops and save as bus_stop_count\nsum() : Used to sum the TRIPS values and save as total_trips\n\nungroup() : Used to end a definition, often use with group_by()\n\n\n\nShow the code\n#weekday morning peak \njoin_df_wkd6_9_group <- join_df0609 %>%\n        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  filter(TRIPS > 0) %>%\n  group_by(grid_id) %>%\n  summarize(\n    bus_stop_count = n(),\n    total_trips = sum(TRIPS)\n  ) %>%\n  ungroup()\n\n#weekday afternoon peak \njoin_df_wkd17_20_group <- join_df1720 %>%\n        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  filter(TRIPS > 0) %>%\n  group_by(grid_id) %>%\n  summarize(\n    bus_stop_count = n(),\n    total_trips = sum(TRIPS)\n  ) %>%\n  ungroup()\n\n#weekend/holiday morning peak \njoin_df_wknd11_14_group <- join_df1114 %>%\n        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  filter(TRIPS > 0) %>%\n  group_by(grid_id) %>%\n  summarize(\n    bus_stop_count = n(),\n    total_trips = sum(TRIPS)\n  ) %>%\n  ungroup()\n\n#weekend/holiday afternoon peak \njoin_df_wknd16_19_group <- join_df1619 %>%\n        mutate(TRIPS = ifelse(is.na(TRIPS), 0, TRIPS)) %>%\n  filter(TRIPS > 0) %>%\n  group_by(grid_id) %>%\n  summarize(\n    bus_stop_count = n(),\n    total_trips = sum(TRIPS)\n  ) %>%\n  ungroup()\n\n\nTo validate that our sf data frame does not contain any missing value, we used any(is.na()) to check :\n\n\nShow the code\ncat('Are there any missing value for Weekday Morning Peak?: ', any(is.na(join_df_wkd6_9_group)),'\\n')\n\n\nAre there any missing value for Weekday Morning Peak?:  FALSE \n\n\nShow the code\ncat('Are there any missing value for Weekday Afternoon Peak?: ', any(is.na(join_df_wkd17_20_group)),'\\n')\n\n\nAre there any missing value for Weekday Afternoon Peak?:  FALSE \n\n\nShow the code\ncat('Are there any missing value for Weekend/Holiday Morning Peak?: ', any(is.na(join_df_wknd11_14_group)),'\\n')\n\n\nAre there any missing value for Weekend/Holiday Morning Peak?:  FALSE \n\n\nShow the code\ncat('Are there any missing value for Weekend/Holiday Afternoon Peak?: ', any(is.na(join_df_wknd16_19_group)),'\\n')\n\n\nAre there any missing value for Weekend/Holiday Afternoon Peak?:  FALSE \n\n\nWe have confirmed that there are no missing values for any of data frame."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#hexagons",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#hexagons",
    "title": "Take Home Exercise 1",
    "section": "HEXAGONS",
    "text": "HEXAGONS"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "The code chunk below load the following packages:\n\ntmap : for thematic mapping\nsf : for geospatial data handling\nsfdep : for spatial dependence for Simple Features\ntidyverse: for non-spatial data handling\nknitr : for dynamic report generation\nplotly : for creating interactive graphs\n\n\npacman::p_load(tmap, sf, sfdep, tidyverse, knitr,plotly)\n\n\n\n\nWe will be using two data sets for this exercise. Data were retrieved on 25th Nov 2023. They are :\n\nHunan , a geospatial data set in ESRI shapefile format, and\nHunan_2012.csv, an attribute data set in csv format\n\nIn this exercise, we are interested to examine the spatial pattern of GDPPC (a.k.a GPD per Capital) of Hunan Provice, People Republic of China.\n\n\nThe code chunk below uses st_read() of sf package to import the 1st data set into R. The imported shapefile will be simple features object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/In-class_Ex/In-class_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nNext, we will import the 2nd dataset (csv) into R. We will use read_csv() of readr package. The output is in R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nAfter importing, we will performed a left_join() with the aid of dplyr package.\n\nhunan_GDPPC <- left_join(hunan,hunan2012) %>%\n    select(1:4,7,15)\n\n\n\n\nWe will be using the qtm() of tmap package to prepare a basemap and a choropleth map to see the distribution of GDPPC 2012 as a form of quick visualization.\n\n\nShow the code\nbasemap <- tm_shape(hunan_GDPPC) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n \ngdppc <- qtm(hunan_GDPPC, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nQueen method is used to derive the contiguity weights:\n\nwm_q <- hunan_GDPPC %>%\n  mutate (nb = st_contiguity(geometry),\n          wt = st_weights(nb, \n                          style = \"W\"),\n          .before = 1)\n\n\n\n\nIn the code chunk below, we will compute local Moran’s I test.\n\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before =1) %>%\n  unnest(local_moran) #to unnest individual columns"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#importing-the-data",
    "title": "In-class Exercise 2",
    "section": "1. Importing the data",
    "text": "1. Importing the data\nWe will be using the Hunan_GDPPC data for this exercise.\n\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#create-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#create-a-time-series-cube",
    "title": "In-class Exercise 2",
    "section": "2. Create a time series cube",
    "text": "2. Create a time series cube\nTo get the concept of spatio-temporal cube, we will be using the spacetime() of sfdep to create a spacetime cube.\n\nGDPPC_st <- spacetime(GDPPC, hunan, \n                       .loc_col = \"County\",\n                       .time_col = \"Year\")\n\nTo confirm if it is spacetime cube, we can check through the following code by using is_spacetime_cube() of sfdep package:\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#compute-gi",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#compute-gi",
    "title": "In-class Exercise 2",
    "section": "3. Compute Gi*",
    "text": "3. Compute Gi*\n\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>% #must-do this first to activate \n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb,geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\nWe can use the new columns to manually calculate the local Gi*. We can do so by grouping by year and using local_gstar_perm() of spdep. Thereafter, we will use unnest() to unnest gi_star column of the newly created gi_starts data frame.\n\ngi_stars <- GDPPC_nb %>%\n  group_by(Year) %>%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %>%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#mann-kendall-test",
    "title": "In-class Exercise 2",
    "section": "4. Mann-Kendall Test",
    "text": "4. Mann-Kendall Test\nWith these Gi* measures, we can evaluate each location for a trend using the Mann-Kendall test. The code chunk below uses Changsha county.\n\ncbg <- gi_stars %>%\n  ungroup() %>%\n  filter(County == \"Changsha\") |>\n  select(County, Year, gi_star)\n\nNext, we will plot the result by using ggplot2 functions.\n\np <- ggplot(data = cbg,\n            aes(x = Year,\n                y = gi_star)) +\n  geom_line() + \n  theme_light()\n \nggplotly(p)\n\n\n\n\n\nNote: we could need to install kendall package. (Install packages via tools > cran as I am not able to run on pacman due to version issues)\n\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 0.485 0.00742    66  136.  589."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#perform-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#perform-emerging-hotspot-analysis",
    "title": "In-class Exercise 2",
    "section": "5. Perform Emerging Hotspot Analysis",
    "text": "5. Perform Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object c (i.e GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation is performed.\n\nehsa <- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim =99\n  )\n\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\nWe could observe that the sporadic coldspot has the higher number of county."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#visualizing-ehsa",
    "href": "In-class_Ex/In-class_Ex02/In-Class_Ex02.html#visualizing-ehsa",
    "title": "In-class Exercise 2",
    "section": "Visualizing EHSA",
    "text": "Visualizing EHSA\nWe will visualize the geographic distribution EHSA classes. Before we do so, we will need to join both hunna and ehsa together.\n\nhunan_ehsa <- hunan %>%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\nehsa_sig <- hunan_ehsa %>%\n  filter(p_value <0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha =0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The code chunk below load the following packages:\n\ntmap : for thematic mapping\nsf : for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)\n\n\n\n\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus <- read_csv(\"data/origin_destination_bus_202308.csv\")\n\nA quick check of odbus tibble data frame shows that the value in ORIGIN_PT_CODE.\n\nodbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)\n\nodbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\nFor the purpose of this exercise, we will extract commuting flows on weekday between 7 to 9 o’clock.\n\norigtrip_7_9 <- odbus %>%\n  filter(DAY_TYPE == \"WEEKDAY\") %>%\n  filter(TIME_PER_HOUR >= 7 &\n           TIME_PER_HOUR <= 9 ) %>%\n  group_by(ORIGIN_PT_CODE) %>%\n  summarise(TRIPS = sum(TOTAL_TRIPS)) %>%\n  ungroup()\n\nTwo geospatial data will be used in this exercise, they are:\n\nbusstop <- st_read(dsn = 'data', layer = 'BusStop') %>%\n  st_transform(crs= 3414)\n\n\nmpsz <- st_read(dsn = 'data', layer = 'MPSZ-2019') %>%\n  st_transform(crs= 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/In-class_Ex/In-class_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if the packages below are installed into the R environment. If they are, then they will be launched into R.\n\npacman::p_load(tmap, sf, sp, DT, spatstat,\n               performance, reshape2,\n               ggpubr, tidyverse)\n\n\n\n\nWe will be using three data sets for this exercise. Data were retrieved for the following:\n\nod_data_rds, weekday morning peak passenger flows at planning subzone level.\nMPSZ-2019 - Geospatial data that provides the sub-zone boundary of URA Master Plan 2019. To import and save as mpsz.rds\npop.csv, - attribute data\n\nIn this exercise, we are interested to calibrate Spatial Interaction Models (SIMs) to determine factors affecting the public bus passenger flows during the morning peak in Singapore.\n\n\nThe code chunk below uses read_rds() to import od_data.rds that was previously saved in Hands-on Exercise 3 into R.\n\nod_data <- read_rds(\"data/rds/od_data.rds\")\n\n\n\n\nThe code chunk below uses st_read() of sf package to import the data into R. The imported shapefile will be simple features object of sf and save as a output through write_rds().\n\n\nShow the code\nmpsz <- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %>%\n  st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/smu/Rworkshop/jiawenoh/ISSS624/In-class_Ex/In-class_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nShow the code\nwrite_rds(mpsz, \"data/rds/mpsz.rds\")\nmpsz <- read_rds(\"data/rds/mpsz.rds\")\n\n\n\n\n\nNext, we will import the population data with the use of read_csv().\n\npop <- read_csv(\"data/aspatial/pop.csv\")\n\n\n\n\n\nA distance matrix is a table that shows the distance between pairs of locations by computing a distance matrix by using URA Master Plan 2019 Planning Subzone boundary.\n\n\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp <- as(mpsz, \"Spatial\")\n\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n\n\nNext, spDists() of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.\n\ndist <- spDists(mpsz_sp, \n                longlat = FALSE)\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\n\n\n\nWe will create a list sorted according to the the distance matrix by planning sub-zone code\n\nsz_names <- mpsz$SUBZONE_C\n\nThen, we will attach SUBZONE_C to row and column for distance matrix matching ahead\n\ncolnames(dist) <- paste0(sz_names)\nrownames(dist) <- paste0(sz_names)\n\n\n\n\nNext, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.\n\ndistPair <- melt(dist) %>%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\n\n\n\nWe are going to append a constant value to replace the intra-zonal distance of 0.\nFirst, we will select and find out the minimum value of the distance by using summary().\n\ndistPair %>%\n  filter(dist > 0) %>%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nNext, a constant distance value of 50m is added into intra-zones distance.\n\ndistPair$dist <- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below is used to rename the origin and destination fields.\n\n\nShow the code\n# to check the distPair data frame\ndistPair %>%\n  summary()\n\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\nShow the code\n#to rename the fields\ndistPair <- distPair %>%\n  rename(orig = Var1,\n         dest = Var2)\n\n#to save output to rds \nwrite_rds(distPair, \"data/rds/distPair.rds\") \ndistPair <- read_rds(\"data/rds/distPair.rds\")\n\n\n\n\n\n\nTo get the flow data, we will compute the total passenger trip between and within planning subzones by using the code chunk below. The output will be flow_data. In addition, we will use head() to display the top 10 data frame.\n\nflow_data <- od_data %>%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %>% \n  summarize(TRIPS = sum(MORNING_PEAK)) \n\nhead(flow_data, 10)\n\n# A tibble: 10 × 3\n# Groups:   ORIGIN_SZ [1]\n   ORIGIN_SZ DESTIN_SZ TRIPS\n   <chr>     <chr>     <dbl>\n 1 AMSZ01    AMSZ01     2694\n 2 AMSZ01    AMSZ02    10591\n 3 AMSZ01    AMSZ03    14980\n 4 AMSZ01    AMSZ04     3106\n 5 AMSZ01    AMSZ05     7734\n 6 AMSZ01    AMSZ06     2306\n 7 AMSZ01    AMSZ07     1824\n 8 AMSZ01    AMSZ08     2734\n 9 AMSZ01    AMSZ09     2300\n10 AMSZ01    AMSZ10      164\n\n\n\n\nWe will use ifelse()function to add three new fields in the dataframe with the condition that if Origin SZ matches Destination SZ, it will be force with 0.\n\nflow_data$FlowNoIntra <- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset <- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)\n\n\n\n\nBefore we proceed, we need to convert the data type for ORIGIN_SZ and DESTIN_SZ from <chr> to <fct> data type.\n\nflow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)\n\nThen, left_join() of dplyr will be used to flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 <- flow_data %>%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex03/data/geospatial/MPSZ-2019.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#commuting-flows",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#commuting-flows",
    "title": "Take Home Exercise 1",
    "section": "3.1 Commuting flows",
    "text": "3.1 Commuting flows\nWe will now plot the choropleth map using tmap and compare between quantile and jenks classification. Quantile maps try to arrange groups so they have the same quantity. As a result, the shading will look equally distributed in quantile types of maps. Jenks map is an optimization method for choropleth maps as it arranges each grouping so there is less variation in each class or shading.\nIn the code chuck below, we will use tmap to plot the spatial distribution of the passenger volume (Total Trips) based on the hexagon grid. We will use tmap_arrange() to show the plots together.\n\nQuantileJenks\n\n\n\n\nShow the code\n#weekday morning peak \nplot0609 <- tm_shape(join_df_wkd6_9_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekday Morning Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekday afternoon peak \nplot1720 <- tm_shape(join_df_wkd17_20_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekday Afternoon Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekend/holiday morning peak \nplot1114 <- tm_shape(join_df_wknd11_14_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekend/Holiday Morning Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekend/holiday afternoon peak \nplot1619 <- tm_shape(join_df_wknd16_19_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekend/Holiday Afternoon Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15,       \n             position = c(\"left\", \"bottom\"))\n\ntmap_arrange(plot0609, plot1720, plot1114, plot1619, asp=2, ncol=2)\n\n\n\n\n\n\n\n\n\nShow the code\n#weekday morning peak \nplot0609j <- tm_shape(join_df_wkd6_9_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekday Morning Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekday afternoon peak \nplot1720j <- tm_shape(join_df_wkd17_20_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekday Afternoon Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekend/holiday morning peak \nplot1114j <- tm_shape(join_df_wknd11_14_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekend/Holiday Morning Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15, \n             position = c(\"left\", \"bottom\"))\n\n#weekend/holiday afternoon peak \nplot1619j <- tm_shape(join_df_wknd16_19_group) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"total_trips\", \n          style = \"jenks\", \n          palette = \"Reds\",\n          title = \"Total Trips\") +\n  tm_layout(main.title = \"Weekend/Holiday Afternoon Peak passenger trips by Origin\",\n            main.title.position = \"center\",\n            main.title.fontface = \"bold\",\n            main.title.size = 0.6,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            frame = TRUE) +\n  tm_credits(\"Source: Population data from \\n Department of Statistics (DOS)\", \n             fontface = \"italic\",  \n             size = 0.15,       \n             position = c(\"left\", \"bottom\"))\n\ntmap_arrange(plot0609j, plot1720j, plot1114j, plot1619j, asp=2, ncol=2)\n\n\n\n\n\n\n\n\nObservations:\nBy looking at the 4 quantitle chloropleth maps (in blue), we could infer the following:\n\nPassenger volume is significantly higher on Weekday than Weekends/Holidays. It ranges around 400k-550k on Weekdays and 110k-150k on Weekends/Holidays.\nMajority of the bus stops in the Central and Southern region of Singapore have a relatively higher passenger volume compared to other regions.\n\n\n\nA quick visualization from the mapview in Section 2.3.2 revealed the location in the red circle as Woodlands - Johor Bahru, Malaysia while the red rectangle is in Tanan Merah. Interestingly, as seen in the red circle, the volume have not declined regardless of time period. People are still travelling to Johor Bahru, Malaysia at any given point.\nOn the contrary, as seen in the red rectangle, the volume changes. It peaks during the Weekend/Holiday period compared to Weekdays. which could be a popular hangout for people over the weekends.\n\nAs observed in Section 3, our data are skewed to one end. Thus, it is not as ideal for us to use the quantile data classification method. We will look at the 4 jenks chloropleth maps (in red).\n\n\nAs identified earlier in the quantile map about the red rectangle at Tanan Merah, we noted the peak is only on the Weekend/Holiday Afternoon. Based on the natural grouping in the data, we are affirmed that the passenger volume towards Johor Bahru, Malaysia remains at the peak throughout the week, and throughout the day.\nFrom the Jenks Classification maps, we have two new observations. From the red and blue circle, we identified that the passenger volume surge on Weekday Morning Peak hour.\nIn comparison, there are more bus stops with higher passenger volume in Weekday Morning followed by Weekend/Holiday Afternoon."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#define-neighborhood",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#define-neighborhood",
    "title": "Take Home Exercise 1",
    "section": "4.1 Define Neighborhood",
    "text": "4.1 Define Neighborhood\nPrior to the test, we would need to determine which locations are considered neighbors. We used the queen method of the spdep:: poly2nb() package to compute contiguity spatial weights to identify adjacent neighbors.\n\nWeekday (0600-0900)Weekday (1700-2000)Weekends/Holidays (1100-1400)Weekends/Holidays (1600-1900)\n\n\n\nwm_q0609 <- poly2nb(join_df_wkd6_9_group, queen=TRUE)\nsummary(wm_q0609)\n\nNeighbour list object:\nNumber of regions: 1493 \nNumber of nonzero links: 6726 \nPercentage nonzero weights: 0.301743 \nAverage number of links: 4.505023 \n12 regions with no links:\n276 296 454 550 713 964 1030 1388 1478 1481 1485 1493\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n 12  40 102 207 286 359 487 \n40 least connected regions:\n1 7 22 38 98 166 183 184 185 191 207 214 253 257 260 551 595 629 683 695 719 738 755 771 855 990 1004 1005 1029 1069 1194 1437 1444 1455 1473 1474 1476 1479 1483 1492 with 1 link\n487 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 55 60 63 67 73 77 80 81 84 85 87 88 91 92 97 102 107 111 117 121 127 132 138 139 141 145 146 147 151 152 153 154 160 161 162 170 171 172 179 180 181 187 188 189 190 196 197 198 201 202 203 204 212 225 235 239 240 242 252 268 272 280 287 289 290 291 293 299 300 302 303 306 311 314 315 317 327 328 329 330 333 342 345 353 358 380 381 390 392 393 397 404 408 413 415 421 426 427 428 430 433 440 441 442 450 456 457 458 459 463 467 470 471 478 482 483 485 491 492 496 502 503 506 507 512 518 523 528 532 537 538 539 541 545 547 553 557 562 563 565 566 570 579 580 583 587 588 592 593 597 603 607 611 613 620 623 624 625 635 636 637 641 642 644 645 646 656 657 658 664 667 668 669 674 675 677 678 687 688 691 692 693 700 703 704 711 714 715 716 727 728 742 744 745 747 758 761 762 763 764 769 770 774 775 776 779 780 781 782 786 787 792 793 796 797 798 799 805 806 809 810 811 816 817 818 827 829 830 832 833 834 836 837 838 839 840 846 849 851 852 853 857 858 862 863 864 866 867 868 870 871 874 877 879 882 885 888 890 891 895 899 904 906 911 912 913 915 916 920 928 929 930 931 932 933 938 942 943 946 947 952 953 955 956 957 961 967 968 969 970 971 973 979 980 981 982 987 994 995 996 997 1007 1008 1009 1011 1012 1019 1020 1021 1025 1033 1034 1037 1039 1040 1045 1046 1047 1049 1050 1051 1052 1059 1061 1062 1063 1066 1072 1076 1083 1084 1085 1088 1089 1093 1094 1100 1103 1104 1105 1111 1116 1117 1118 1119 1124 1125 1127 1128 1129 1130 1131 1133 1139 1140 1141 1145 1146 1147 1149 1151 1152 1153 1154 1158 1159 1160 1161 1162 1166 1168 1171 1172 1173 1174 1175 1181 1182 1183 1184 1185 1186 1187 1190 1191 1197 1198 1199 1200 1201 1207 1213 1214 1215 1219 1224 1225 1231 1233 1234 1235 1240 1244 1245 1250 1251 1252 1256 1259 1261 1267 1276 1279 1280 1281 1294 1299 1300 1301 1302 1304 1305 1306 1309 1310 1312 1318 1327 1329 1330 1338 1339 1341 1344 1345 1350 1353 1354 1355 1357 1361 1364 1366 1368 1371 1379 1381 1385 1390 1391 1393 1397 1398 1399 1400 1401 1406 1407 1408 1409 1413 1414 1415 1419 1420 1422 1424 1426 1429 1430 1432 1433 1434 1435 1442 with 6 links\n\n\n\n\n\nwm_q1720 <- poly2nb(join_df_wkd17_20_group, queen=TRUE)\nsummary(wm_q1720)\n\nNeighbour list object:\nNumber of regions: 1495 \nNumber of nonzero links: 6734 \nPercentage nonzero weights: 0.3012942 \nAverage number of links: 4.504348 \n12 regions with no links:\n277 297 455 551 714 965 1032 1390 1480 1483 1487 1495\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n 12  37 107 206 287 359 487 \n37 least connected regions:\n1 7 22 38 98 166 184 192 208 215 254 258 261 552 596 630 684 696 720 739 756 772 856 1006 1007 1031 1071 1196 1439 1446 1457 1475 1476 1478 1481 1485 1494 with 1 link\n487 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 55 60 63 67 73 77 80 81 84 85 87 88 91 92 97 102 107 111 117 121 127 132 138 139 141 145 146 147 151 152 153 154 160 161 162 170 171 172 180 181 182 188 189 190 191 197 198 199 202 203 204 205 213 226 236 240 241 243 253 269 273 281 288 290 291 292 294 300 301 303 304 307 312 315 316 318 328 329 330 331 334 343 346 354 359 381 382 391 393 394 398 405 409 414 416 422 427 428 429 431 434 441 442 443 451 457 458 459 460 464 468 471 472 479 483 484 486 492 493 497 503 504 507 508 513 519 524 529 533 538 539 540 542 546 548 554 558 563 564 566 567 571 580 581 584 588 589 593 594 598 604 608 612 614 621 624 625 626 636 637 638 642 643 645 646 647 657 658 659 665 668 669 670 675 676 678 679 688 689 692 693 694 701 704 705 712 715 716 717 728 729 743 745 746 748 759 762 763 764 765 770 771 775 776 777 780 781 782 783 787 788 793 794 797 798 799 800 806 807 810 811 812 817 818 819 828 830 831 833 834 835 837 838 839 840 841 847 850 852 853 854 858 859 863 864 865 867 868 869 871 872 875 878 880 883 886 889 891 892 896 900 905 907 912 913 914 916 917 921 929 930 931 932 933 934 939 943 944 947 948 953 954 956 957 958 962 969 970 971 972 973 975 981 982 983 984 989 996 997 998 999 1009 1010 1011 1013 1014 1021 1022 1023 1027 1035 1036 1039 1041 1042 1047 1048 1049 1051 1052 1053 1054 1061 1063 1064 1065 1068 1074 1078 1085 1086 1087 1090 1091 1095 1096 1102 1105 1106 1107 1113 1118 1119 1120 1121 1126 1127 1129 1130 1131 1132 1133 1135 1141 1142 1143 1147 1148 1149 1151 1153 1154 1155 1156 1160 1161 1162 1163 1164 1168 1170 1173 1174 1175 1176 1177 1183 1184 1185 1186 1187 1188 1189 1192 1193 1199 1200 1201 1202 1203 1209 1215 1216 1217 1221 1226 1227 1233 1235 1236 1237 1242 1246 1247 1252 1253 1254 1258 1261 1263 1269 1278 1281 1282 1283 1296 1301 1302 1303 1304 1306 1307 1308 1311 1312 1314 1320 1329 1331 1332 1340 1341 1343 1346 1347 1352 1355 1356 1357 1359 1363 1366 1368 1370 1373 1381 1383 1387 1392 1393 1395 1399 1400 1401 1402 1403 1408 1409 1410 1411 1415 1416 1417 1421 1422 1424 1426 1428 1431 1432 1434 1435 1436 1437 1444 with 6 links\n\n\n\n\n\nwm_q1114 <- poly2nb(join_df_wknd11_14_group, queen=TRUE)\nsummary(wm_q1114)\n\nNeighbour list object:\nNumber of regions: 1499 \nNumber of nonzero links: 6734 \nPercentage nonzero weights: 0.2996883 \nAverage number of links: 4.492328 \n11 regions with no links:\n297 454 550 712 963 1030 1394 1484 1487 1491 1499\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n 11  41 109 206 286 363 483 \n41 least connected regions:\n1 7 22 38 96 164 180 181 182 188 204 211 250 251 256 259 277 551 594 628 682 694 718 737 754 770 854 1004 1005 1029 1069 1196 1443 1450 1461 1479 1480 1482 1485 1489 1498 with 1 link\n483 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 54 59 62 66 72 76 79 80 83 86 87 89 100 105 109 115 119 125 130 136 137 139 143 144 145 150 151 152 159 160 167 168 169 176 177 178 184 185 186 187 193 194 195 198 199 200 201 209 222 232 236 237 239 249 269 273 281 288 290 291 292 294 300 301 303 304 307 312 315 316 318 328 329 330 331 334 343 346 354 359 381 382 391 393 394 397 404 408 413 415 421 426 427 428 430 433 440 441 442 450 456 457 458 459 463 467 470 471 478 482 483 485 491 492 496 502 503 506 507 512 518 523 528 532 537 538 539 541 545 547 552 556 562 564 565 569 578 579 582 586 587 591 592 596 602 606 610 612 619 622 623 624 634 635 636 640 641 643 644 645 655 656 657 663 666 667 668 673 674 676 677 686 687 690 691 692 699 702 703 710 713 714 715 726 727 741 743 744 746 757 760 761 762 763 768 769 773 774 775 778 779 780 781 785 786 791 792 795 796 797 798 804 805 808 809 810 815 816 817 826 828 829 831 832 833 835 836 837 838 839 845 848 850 851 852 856 857 861 862 863 865 866 867 869 870 873 876 878 881 884 887 889 890 894 898 903 905 910 911 912 914 915 919 927 928 929 930 931 932 937 941 942 945 946 951 952 954 955 956 960 967 968 969 970 971 973 979 980 981 982 987 994 995 996 997 1007 1008 1009 1011 1012 1019 1020 1021 1025 1033 1034 1037 1039 1040 1045 1046 1047 1049 1050 1051 1052 1059 1061 1062 1063 1066 1072 1076 1083 1084 1085 1088 1089 1093 1094 1100 1103 1104 1105 1111 1116 1117 1118 1119 1124 1125 1127 1128 1129 1130 1131 1133 1139 1140 1141 1145 1146 1147 1149 1152 1153 1154 1155 1159 1160 1161 1162 1163 1167 1169 1172 1173 1174 1175 1176 1183 1184 1185 1186 1187 1188 1189 1192 1193 1199 1200 1201 1202 1203 1209 1215 1216 1217 1221 1226 1227 1233 1235 1236 1237 1243 1247 1248 1253 1254 1255 1259 1262 1264 1270 1279 1281 1282 1283 1284 1296 1298 1304 1305 1306 1307 1309 1310 1311 1314 1315 1317 1323 1332 1334 1335 1344 1345 1347 1350 1351 1356 1359 1360 1361 1363 1367 1370 1372 1374 1377 1385 1387 1391 1396 1397 1399 1403 1404 1405 1406 1407 1412 1413 1414 1415 1419 1420 1421 1425 1426 1428 1430 1432 1435 1436 1438 1439 1440 1441 1448 with 6 links\n\n\n\n\n\nwm_q1619 <- poly2nb(join_df_wknd16_19_group, queen=TRUE)\nsummary(wm_q1619)\n\nNeighbour list object:\nNumber of regions: 1489 \nNumber of nonzero links: 6688 \nPercentage nonzero weights: 0.3016525 \nAverage number of links: 4.491605 \n11 regions with no links:\n300 457 553 712 960 1026 1390 1476 1479 1483 1489\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n 11  42 108 208 277 360 483 \n42 least connected regions:\n1 7 22 38 98 166 183 184 185 191 207 214 253 254 259 262 280 554 596 629 682 694 718 737 754 770 805 851 986 1000 1001 1025 1065 1192 1439 1446 1456 1471 1472 1474 1477 1481 with 1 link\n483 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 55 60 63 67 73 77 80 81 84 85 87 88 91 92 97 102 107 111 117 121 127 132 138 139 141 145 146 147 151 152 153 154 160 161 162 170 171 172 179 180 181 187 188 189 190 196 197 198 201 202 203 204 212 225 235 239 240 242 252 272 276 284 291 293 294 295 297 303 304 306 307 310 315 318 319 321 331 332 333 334 337 346 349 357 362 384 385 394 396 397 400 407 411 416 418 424 429 430 431 433 436 443 444 445 453 459 460 461 462 466 470 473 474 481 485 486 488 494 495 499 505 506 509 510 515 521 526 531 535 540 541 542 544 548 550 555 559 565 567 568 572 581 582 585 589 590 593 594 598 604 608 611 613 620 623 624 625 634 635 636 640 643 644 645 655 656 657 663 666 667 668 673 674 676 677 686 687 690 691 692 699 702 703 710 713 714 715 726 727 741 743 744 746 757 760 761 762 763 768 769 773 774 775 778 779 780 781 785 786 790 791 794 795 796 797 803 804 806 807 808 813 814 815 824 828 829 830 832 833 834 835 836 842 847 848 849 853 854 858 859 860 862 863 866 867 870 873 875 878 881 884 886 887 891 895 900 902 907 908 909 911 912 916 924 925 926 927 928 929 934 938 939 942 943 948 949 951 952 953 957 963 964 965 966 967 969 975 976 977 978 983 990 991 992 993 1003 1004 1005 1007 1008 1015 1016 1017 1021 1029 1030 1033 1035 1036 1041 1042 1043 1045 1046 1047 1048 1055 1057 1058 1059 1062 1068 1072 1079 1080 1081 1084 1085 1089 1090 1096 1099 1100 1101 1107 1112 1113 1114 1115 1120 1121 1123 1124 1125 1126 1127 1129 1135 1136 1137 1141 1142 1143 1145 1148 1149 1150 1151 1155 1156 1157 1158 1159 1163 1165 1168 1169 1170 1171 1172 1179 1180 1181 1182 1183 1184 1185 1188 1189 1195 1196 1197 1198 1199 1205 1211 1212 1213 1217 1222 1223 1229 1231 1232 1233 1239 1243 1244 1249 1250 1251 1255 1258 1260 1266 1275 1277 1278 1279 1280 1292 1294 1300 1301 1302 1303 1305 1306 1307 1310 1311 1313 1319 1328 1330 1331 1340 1341 1343 1346 1347 1352 1355 1356 1357 1359 1363 1366 1368 1370 1373 1381 1383 1387 1392 1393 1395 1399 1400 1401 1402 1403 1408 1409 1410 1411 1415 1416 1417 1421 1422 1424 1426 1428 1431 1432 1434 1435 1436 1437 1444 with 6 links\n\n\n\n\n\nFrom the summary above, we can see that on average each area is contigious with about 4 other grids. However, there are 11/12 regions area which does not have any contigious neighbors. Therefore, we would not be using the above for further analysis."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#deriving-the-centriod",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#deriving-the-centriod",
    "title": "Take Home Exercise 1",
    "section": "4.2 Deriving the centriod",
    "text": "4.2 Deriving the centriod\nTo begin, we will retrieve the centroid for each area of the commuting flows. We will used the st_centroid() function to calculate the geometric center of a spatial object.\n\n\nShow the code\n#weekday morning peak \ncoords0609 <- st_centroid(st_geometry(join_df_wkd6_9_group))\ncoords0609[1]\n\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 28214.15 xmax: 3970.122 ymax: 28214.15\nProjected CRS: SVY21 / Singapore TM\n\n\nShow the code\n#weekday afternoon peak \ncoords1720 <- st_centroid(st_geometry(join_df_wkd17_20_group))\ncoords1720[1]\n\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 28214.15 xmax: 3970.122 ymax: 28214.15\nProjected CRS: SVY21 / Singapore TM\n\n\nShow the code\n#weekend/holiday morning peak \ncoords1114 <- st_centroid(st_geometry(join_df_wknd11_14_group))\ncoords1114[1]\n\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 28214.15 xmax: 3970.122 ymax: 28214.15\nProjected CRS: SVY21 / Singapore TM\n\n\nShow the code\n#weekend/holiday afternoon peak \ncoords1619 <- st_centroid(st_geometry(join_df_wknd16_19_group))\ncoords1619[1]\n\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 28214.15 xmax: 3970.122 ymax: 28214.15\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#determine-the-cut-off-distance",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#determine-the-cut-off-distance",
    "title": "Take Home Exercise 1",
    "section": "4.3 Determine the cut-off distance",
    "text": "4.3 Determine the cut-off distance\nWe will be using knearneigh() of spdep to identify the k nearest neighbors of each other. If longlat = TRUE, it computes the Euclidean distance with a lower and upper bounds by doing the following:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nWeekday (0600-0900)Weekday (1700-2000)Weekends/Holidays (1100-1400)Weekends/Holidays (1600-1900)\n\n\n\nk0609 <- knn2nb(knearneigh(coords0609, k = 1))\nk0609dists <- unlist(nbdists(k0609, coords0609))\nsummary(k0609dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  500.0   500.0   500.0   507.2   500.0  4582.6 \n\n\n\n\n\nk1720 <- knn2nb(knearneigh(coords1720, k = 1))\nk1720dists <- unlist(nbdists(k1720, coords1720))\nsummary(k1720dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  500.0   500.0   500.0   507.2   500.0  4582.6 \n\n\n\n\n\nk1114 <- knn2nb(knearneigh(coords1114, k = 1))\nk1114dists <- unlist(nbdists(k1114, coords1114))\nsummary(k1114dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    500     500     500     507     500    4583 \n\n\n\n\n\nk1619 <- knn2nb(knearneigh(coords1619, k = 1))\nk1619dists <- unlist(nbdists(k1619, coords1619))\nsummary(k1619dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    500     500     500     507     500    4583 \n\n\n\n\n\nFrom the summary reports above, the largest first nearest neighbor distance is 4,582km (lowest value among the four commuting flows). Thus, we will use this as the upper threshold such that all units will have at least one neighbor.\nAs observed, the results for the commuting flows seems identical. As such, we will be showing - Weekday Morning Peak (0600-0900) unless there are major differences."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-fixed-distance-weight-matrix",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-fixed-distance-weight-matrix",
    "title": "Take Home Exercise 1",
    "section": "4.4 Computing Fixed distance weight matrix",
    "text": "4.4 Computing Fixed distance weight matrix\nWith the upper threshold, we will be able to compute the fixed distance weight matrix. We will compute the distance weight matrix by using dnearneigh() as shown below.\n\n\nShow the code\n#weekday morning peak \nwm_d0609 <- dnearneigh(coords0609,0,4582)\n#weekday afternoon peak \nwm_d1720 <- dnearneigh(coords1720,0,4582)\n#weekend/holiday morning peak \nwm_d1114 <- dnearneigh(coords1114,0,4582)\n#weekend/holiday afternoon peak \nwm_d1619 <- dnearneigh(coords1619,0,4582)\n\n#example of 1 commuting flow \nwm_d0609\n\n\nNeighbour list object:\nNumber of regions: 1493 \nNumber of nonzero links: 229408 \nPercentage nonzero weights: 10.29174 \nAverage number of links: 153.6557 \n1 region with no links:\n296\n\n\nAcross the commuting flows, we identify an average of 153 neighbors per grid using the distance based weight matrix.\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\n#weekday morning peak \nwm0609_lw <- nb2listw(wm_d0609, style = 'B',zero.policy = TRUE)\n\n#weekday afternoon peak \nwm1720_lw <- nb2listw(wm_d1720, style = 'B',zero.policy = TRUE)\n\n#weekend/holiday morning peak \nwm1114_lw <- nb2listw(wm_d1114, style = 'B',zero.policy = TRUE)\n\n#weekend/holiday afternoon peak \nwm1619_lw <- nb2listw(wm_d1619, style = 'B',zero.policy = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-adaptive-distance-weight-matrix",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#computing-adaptive-distance-weight-matrix",
    "title": "Take Home Exercise 1",
    "section": "4.5 Computing Adaptive distance weight matrix",
    "text": "4.5 Computing Adaptive distance weight matrix\nAlternatively, we could directly control the number of neighbors using k-nearest neighbors by using knearneigh() function. For our analysis, we will set the number of neighbors to 8.\n\n\nShow the code\n#weekday morning peak \nknn0609 <- knn2nb(knearneigh(coords0609, k=8))\n#weekday afternoon peak \nknn1720 <- knn2nb(knearneigh(coords1720, k=8))\n#weekend/holiday morning peak \nknn1114 <- knn2nb(knearneigh(coords1114, k=8))\n#weekend/holiday afternoon peak \nknn1619 <- knn2nb(knearneigh(coords1619, k=8))\n\n#example of 1 commuting flow \nknn0609\n\n\nNeighbour list object:\nNumber of regions: 1493 \nNumber of nonzero links: 11944 \nPercentage nonzero weights: 0.5358339 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\n#weekday morning peak \nknn0609_lw <- nb2listw(knn0609, style = 'B')\n#weekday afternoon peak \nknn1720_lw <- nb2listw(knn1720, style = 'B')\n#weekend/holiday morning peak \nknn1114_lw <- nb2listw(knn1114, style = 'B')\n#weekend/holiday afternoon peak \nknn1619_lw <- nb2listw(knn1619, style = 'B')\n\n#example of 1 commuting flow \nsummary(knn0609_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1493 \nNumber of nonzero links: 11944 \nPercentage nonzero weights: 0.5358339 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n   8 \n1493 \n1493 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 with 8 links\n1493 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 with 8 links\n\nWeights style: B \nWeights constants summary:\n     n      nn    S0    S1     S2\nB 1493 2229049 11944 22284 387046"
  }
]